============================= test session starts ==============================
platform linux -- Python 3.13.7, pytest-9.0.1, pluggy-1.6.0 -- /mnt/projects/aris-tool/.venv/bin/python3.13
cachedir: .pytest_cache
rootdir: /mnt/projects/aris-tool
configfile: pyproject.toml
plugins: anyio-4.11.0, cov-7.0.0
collecting ... collected 512 items

tests/integration/test_cli_integration.py::TestCLIIntegration::test_full_initialization_workflow FAILED [  0%]
tests/integration/test_cli_integration.py::TestCLIIntegration::test_status_after_init FAILED [  0%]
tests/integration/test_cli_integration.py::TestCLIIntegration::test_json_output_mode FAILED [  0%]
tests/integration/test_cli_integration.py::TestCLIIntegration::test_db_commands_workflow FAILED [  0%]
tests/integration/test_cli_integration.py::TestCLIIntegration::test_git_commands_workflow PASSED [  0%]
tests/integration/test_cli_integration.py::TestCLIIntegration::test_placeholder_commands_accessible FAILED [  1%]
tests/integration/test_cli_integration.py::TestCLIIntegration::test_config_integration PASSED [  1%]
tests/integration/test_cli_integration.py::TestCLIIntegration::test_error_handling PASSED [  1%]
tests/integration/test_cli_integration.py::TestCLIIntegration::test_help_for_all_commands PASSED [  1%]
tests/integration/test_cli_integration.py::TestCLIErrorHandling::test_status_without_init PASSED [  1%]
tests/integration/test_cli_integration.py::TestCLIErrorHandling::test_show_nonexistent_document PASSED [  2%]
tests/integration/test_cli_integration.py::TestCLIOutputFormats::test_verbose_output FAILED [  2%]
tests/integration/test_cli_integration.py::TestCLIOutputFormats::test_json_vs_rich_output PASSED [  2%]
tests/integration/test_complete_workflow.py::TestCompleteWorkflow::test_query_to_document_creation_workflow ERROR [  2%]
tests/integration/test_complete_workflow.py::TestCompleteWorkflow::test_query_to_deduplication_and_update ERROR [  2%]
tests/integration/test_complete_workflow.py::TestCompleteWorkflow::test_workflow_git_integration ERROR [  3%]
tests/integration/test_complete_workflow.py::TestDeduplicationGateIntegration::test_duplicate_detection_workflow ERROR [  3%]
tests/integration/test_complete_workflow.py::TestDeduplicationGateIntegration::test_deduplication_action_execution ERROR [  3%]
tests/integration/test_complete_workflow.py::TestSessionPersistence::test_session_creation_and_persistence ERROR [  3%]
tests/integration/test_complete_workflow.py::TestSessionPersistence::test_session_resume ERROR [  3%]
tests/integration/test_complete_workflow.py::TestSessionPersistence::test_session_state_updates ERROR [  4%]
tests/integration/test_complete_workflow.py::TestSessionPersistence::test_multiple_session_isolation ERROR [  4%]
tests/integration/test_complete_workflow.py::TestCostTrackingAndBudget::test_cost_tracker_initialization PASSED [  4%]
tests/integration/test_complete_workflow.py::TestCostTrackingAndBudget::test_cost_operation_tracking FAILED [  4%]
tests/integration/test_complete_workflow.py::TestCostTrackingAndBudget::test_budget_limit_enforcement FAILED [  4%]
tests/integration/test_complete_workflow.py::TestCostTrackingAndBudget::test_cost_tracking_in_workflow ERROR [  5%]
tests/integration/test_complete_workflow.py::TestQualityValidationAndConfidence::test_confidence_scoring_in_workflow ERROR [  5%]
tests/integration/test_complete_workflow.py::TestQualityValidationAndConfidence::test_document_quality_metrics ERROR [  5%]
tests/integration/test_complete_workflow.py::TestQualityValidationAndConfidence::test_early_stopping_on_confidence ERROR [  5%]
tests/integration/test_complete_workflow.py::TestPerformanceBenchmarks::test_workflow_execution_time ERROR [  5%]
tests/integration/test_complete_workflow.py::TestPerformanceBenchmarks::test_document_store_batch_performance ERROR [  6%]
tests/integration/test_complete_workflow.py::TestPerformanceBenchmarks::test_deduplication_performance_scaling ERROR [  6%]
tests/integration/test_complete_workflow.py::TestPerformanceBenchmarks::test_session_recovery_time ERROR [  6%]
tests/integration/test_complete_workflow.py::TestIntegrationStress::test_concurrent_research_queries ERROR [  6%]
tests/integration/test_complete_workflow.py::TestIntegrationStress::test_large_document_handling ERROR [  6%]
tests/integration/test_complete_workflow.py::TestCriticalPaths::test_research_failure_recovery ERROR [  7%]
tests/integration/test_complete_workflow.py::TestCriticalPaths::test_document_update_failure_handling ERROR [  7%]
tests/integration/test_complete_workflow.py::TestCriticalPaths::test_git_operation_failure_handling FAILED [  7%]
tests/integration/test_complete_workflow.py::TestIntegrationHelpers::test_mock_tavily_client_functionality PASSED [  7%]
tests/integration/test_complete_workflow.py::TestIntegrationHelpers::test_mock_sequential_client_functionality PASSED [  7%]
tests/integration/test_complete_workflow.py::TestIntegrationHelpers::test_config_validation ERROR [  8%]
tests/integration/test_critical_paths.py::TestCriticalPath_QueryIngestion::test_query_acceptance_and_validation ERROR [  8%]
tests/integration/test_critical_paths.py::TestCriticalPath_QueryIngestion::test_session_initialization ERROR [  8%]
tests/integration/test_critical_paths.py::TestCriticalPath_Deduplication::test_duplicate_detection_flow ERROR [  8%]
tests/integration/test_critical_paths.py::TestCriticalPath_Deduplication::test_deduplication_decision_execution ERROR [  8%]
tests/integration/test_critical_paths.py::TestCriticalPath_DocumentStorage::test_document_save_and_retrieve ERROR [  8%]
tests/integration/test_critical_paths.py::TestCriticalPath_DocumentStorage::test_document_integrity_after_retrieval ERROR [  9%]
tests/integration/test_critical_paths.py::TestCriticalPath_DocumentStorage::test_bulk_document_operations ERROR [  9%]
tests/integration/test_critical_paths.py::TestCriticalPath_SessionPersistence::test_session_persistence_cycle ERROR [  9%]
tests/integration/test_critical_paths.py::TestCriticalPath_SessionPersistence::test_session_state_transitions ERROR [  9%]
tests/integration/test_critical_paths.py::TestCriticalPath_CostTracking::test_cost_tracking_accuracy FAILED [  9%]
tests/integration/test_critical_paths.py::TestCriticalPath_CostTracking::test_budget_limit_enforcement FAILED [ 10%]
tests/integration/test_critical_paths.py::TestCriticalPath_GitIntegration::test_git_manager_initialization PASSED [ 10%]
tests/integration/test_critical_paths.py::TestCriticalPath_GitIntegration::test_git_commit_creation PASSED [ 10%]
tests/integration/test_critical_paths.py::TestCriticalPath_GitIntegration::test_git_history_tracking PASSED [ 10%]
tests/integration/test_critical_paths.py::TestCriticalPath_QualityValidation::test_confidence_scoring FAILED [ 10%]
tests/integration/test_critical_paths.py::TestCriticalPath_QualityValidation::test_quality_threshold_enforcement FAILED [ 11%]
tests/integration/test_critical_paths.py::TestCriticalPath_ErrorRecovery::test_error_recording_in_session ERROR [ 11%]
tests/integration/test_critical_paths.py::TestCriticalPath_ErrorRecovery::test_session_recovery_after_failure ERROR [ 11%]
tests/integration/test_document_store.py::TestDocumentSave::test_save_new_document FAILED [ 11%]
tests/integration/test_document_store.py::TestDocumentSave::test_save_creates_directory FAILED [ 11%]
tests/integration/test_document_store.py::TestDocumentSave::test_save_creates_git_commit FAILED [ 12%]
tests/integration/test_document_store.py::TestDocumentSave::test_save_with_custom_commit_message FAILED [ 12%]
tests/integration/test_document_store.py::TestDocumentSave::test_save_update_operation FAILED [ 12%]
tests/integration/test_document_store.py::TestDocumentSave::test_save_preserves_metadata FAILED [ 12%]
tests/integration/test_document_store.py::TestDocumentLoad::test_load_existing_document FAILED [ 12%]
tests/integration/test_document_store.py::TestDocumentLoad::test_load_nonexistent_document_raises_error FAILED [ 13%]
tests/integration/test_document_store.py::TestDocumentLoad::test_load_document_from_commit FAILED [ 13%]
tests/integration/test_document_store.py::TestVersionHistory::test_get_versions_single_version FAILED [ 13%]
tests/integration/test_document_store.py::TestVersionHistory::test_get_versions_multiple_versions FAILED [ 13%]
tests/integration/test_document_store.py::TestVersionHistory::test_get_versions_with_limit FAILED [ 13%]
tests/integration/test_document_store.py::TestDiffOperations::test_diff_between_versions FAILED [ 14%]
tests/integration/test_document_store.py::TestDiffOperations::test_diff_with_current FAILED [ 14%]
tests/integration/test_document_store.py::TestRestoreOperations::test_restore_to_previous_version FAILED [ 14%]
tests/integration/test_document_store.py::TestRestoreOperations::test_restore_creates_backup FAILED [ 14%]
tests/integration/test_document_store.py::TestRepositoryStatus::test_get_status_clean FAILED [ 14%]
tests/integration/test_document_store.py::TestRepositoryStatus::test_get_status_with_uncommitted FAILED [ 15%]
tests/integration/test_document_store.py::TestRepositoryStatus::test_has_uncommitted_changes FAILED [ 15%]
tests/integration/test_document_store.py::TestDocumentList::test_list_all_documents FAILED [ 15%]
tests/integration/test_document_store.py::TestDocumentList::test_list_documents_with_topic_filter FAILED [ 15%]
tests/integration/test_document_store.py::TestDocumentList::test_list_documents_with_status_filter FAILED [ 15%]
tests/integration/test_end_to_end_research.py::TestEndToEndResearch::test_complete_workflow FAILED [ 16%]
tests/integration/test_end_to_end_research.py::TestEndToEndResearch::test_multi_hop_workflow FAILED [ 16%]
tests/integration/test_end_to_end_research.py::TestEndToEndResearch::test_progress_tracking_integration FAILED [ 16%]
tests/integration/test_end_to_end_research.py::TestEndToEndResearch::test_document_creation_integration FAILED [ 16%]
tests/integration/test_end_to_end_research.py::TestEndToEndResearch::test_error_recovery FAILED [ 16%]
tests/integration/test_end_to_end_research.py::TestEndToEndResearch::test_budget_enforcement FAILED [ 16%]
tests/integration/test_end_to_end_research.py::TestReasoningEngineIntegration::test_reasoning_engine_hypothesis_workflow FAILED [ 17%]
tests/integration/test_end_to_end_research.py::TestReasoningEngineIntegration::test_confidence_based_early_stopping FAILED [ 17%]
tests/integration/test_end_to_end_research.py::TestAsyncContextManager::test_context_manager_usage FAILED [ 17%]
tests/integration/test_performance_benchmarks.py::TestDocumentOperationsPerformance::test_single_document_save_performance ERROR [ 17%]
tests/integration/test_performance_benchmarks.py::TestDocumentOperationsPerformance::test_bulk_document_save_performance ERROR [ 17%]
tests/integration/test_performance_benchmarks.py::TestDocumentOperationsPerformance::test_document_retrieval_performance ERROR [ 18%]
tests/integration/test_performance_benchmarks.py::TestDocumentOperationsPerformance::test_document_with_large_content_performance ERROR [ 18%]
tests/integration/test_performance_benchmarks.py::TestDeduplicationPerformance::test_deduplication_check_performance ERROR [ 18%]
tests/integration/test_performance_benchmarks.py::TestDeduplicationPerformance::test_deduplication_scaling_performance ERROR [ 18%]
tests/integration/test_performance_benchmarks.py::TestSessionOperationsPerformance::test_session_creation_performance ERROR [ 18%]
tests/integration/test_performance_benchmarks.py::TestSessionOperationsPerformance::test_session_state_update_performance ERROR [ 19%]
tests/integration/test_performance_benchmarks.py::TestSessionOperationsPerformance::test_session_retrieval_performance ERROR [ 19%]
tests/integration/test_performance_benchmarks.py::TestSessionOperationsPerformance::test_bulk_session_operations_performance ERROR [ 19%]
tests/integration/test_performance_benchmarks.py::TestCostTrackingPerformance::test_cost_operation_tracking_performance FAILED [ 19%]
tests/integration/test_performance_benchmarks.py::TestCostTrackingPerformance::test_cost_summary_generation_performance FAILED [ 19%]
tests/integration/test_performance_benchmarks.py::TestProgressTrackingPerformance::test_hop_recording_performance FAILED [ 20%]
tests/integration/test_performance_benchmarks.py::TestProgressTrackingPerformance::test_stats_computation_performance FAILED [ 20%]
tests/integration/test_performance_benchmarks.py::TestEndToEndWorkflowPerformance::test_workflow_step_timing ERROR [ 20%]
tests/integration/test_reasoning_workflow.py::TestReasoningEngine::test_analyze_query FAILED [ 20%]
tests/integration/test_reasoning_workflow.py::TestReasoningEngine::test_execute_research_hop FAILED [ 20%]
tests/integration/test_reasoning_workflow.py::TestReasoningEngine::test_multi_hop_research_early_stop FAILED [ 21%]
tests/integration/test_reasoning_workflow.py::TestReasoningEngine::test_multi_hop_research_max_hops FAILED [ 21%]
tests/integration/test_reasoning_workflow.py::TestReasoningEngine::test_gather_evidence_error_handling FAILED [ 21%]
tests/integration/test_reasoning_workflow.py::TestReasoningEngine::test_refine_hypothesis FAILED [ 21%]
tests/integration/test_reasoning_workflow.py::TestReasoningEngine::test_generate_follow_up_queries FAILED [ 21%]
tests/integration/test_reasoning_workflow.py::TestReasoningEngine::test_cost_tracking FAILED [ 22%]
tests/integration/test_reasoning_workflow.py::TestReasoningEngine::test_context_management FAILED [ 22%]
tests/integration/test_reasoning_workflow.py::TestReasoningEngine::test_async_context_manager FAILED [ 22%]
tests/integration/test_reasoning_workflow.py::TestReasoningContext::test_add_hop_result PASSED [ 22%]
tests/integration/test_reasoning_workflow.py::TestReasoningContext::test_overall_confidence_calculation PASSED [ 22%]
tests/integration/test_repositories.py::TestRepositories::test_topic_repository PASSED [ 23%]
tests/integration/test_repositories.py::TestRepositories::test_document_repository FAILED [ 23%]
tests/integration/test_repositories.py::TestRepositories::test_source_repository PASSED [ 23%]
tests/integration/test_repositories.py::TestRepositories::test_relationship_repository PASSED [ 23%]
tests/integration/test_repositories.py::TestRepositories::test_research_session_repository FAILED [ 23%]
tests/integration/test_repositories.py::TestRepositories::test_research_hop_repository PASSED [ 24%]
tests/integration/test_repositories.py::TestRepositories::test_conflict_repository PASSED [ 24%]
tests/test_cost_manager.py::TestCostBreakdown::test_cost_breakdown_creation FAILED [ 24%]
tests/test_cost_manager.py::TestCostBreakdown::test_cost_breakdown_to_dict PASSED [ 24%]
tests/test_cost_manager.py::TestBudgetAlert::test_budget_alert_creation PASSED [ 24%]
tests/test_cost_manager.py::TestBudgetAlert::test_budget_alert_to_dict PASSED [ 25%]
tests/test_cost_manager.py::TestCostManager::test_cost_manager_initialization PASSED [ 25%]
tests/test_cost_manager.py::TestCostManager::test_set_pricing PASSED     [ 25%]
tests/test_cost_manager.py::TestCostManager::test_track_hop_cost_with_calculations FAILED [ 25%]
tests/test_cost_manager.py::TestCostManager::test_track_hop_cost_with_overrides FAILED [ 25%]
tests/test_cost_manager.py::TestCostManager::test_budget_threshold_75_percent FAILED [ 25%]
tests/test_cost_manager.py::TestCostManager::test_budget_threshold_90_percent FAILED [ 26%]
tests/test_cost_manager.py::TestCostManager::test_budget_threshold_critical FAILED [ 26%]
tests/test_cost_manager.py::TestCostManager::test_can_perform_operation_within_budget FAILED [ 26%]
tests/test_cost_manager.py::TestCostManager::test_can_perform_operation_exceeds_budget FAILED [ 26%]
tests/test_cost_manager.py::TestCostManager::test_clear_session_cache PASSED [ 26%]
tests/test_cost_manager.py::TestCostIntegration::test_multiple_hops_cost_accumulation FAILED [ 27%]
tests/test_cost_manager.py::TestCostIntegration::test_cost_history_directory_creation PASSED [ 27%]
tests/test_cost_manager.py::TestCostIntegration::test_export_cost_history_json FAILED [ 27%]
tests/test_document_merger.py::TestMergeStrategies::test_merge_append_strategy PASSED [ 27%]
tests/test_document_merger.py::TestMergeStrategies::test_merge_replace_strategy PASSED [ 27%]
tests/test_document_merger.py::TestMergeStrategies::test_merge_integrate_strategy PASSED [ 28%]
tests/test_document_merger.py::TestMergeStrategies::test_invalid_merge_strategy FAILED [ 28%]
tests/test_document_merger.py::TestMetadataMerge::test_merge_topics PASSED [ 28%]
tests/test_document_merger.py::TestMetadataMerge::test_merge_questions FAILED [ 28%]
tests/test_document_merger.py::TestMetadataMerge::test_merge_confidence_higher PASSED [ 28%]
tests/test_document_merger.py::TestMetadataMerge::test_merge_confidence_lower PASSED [ 29%]
tests/test_document_merger.py::TestMetadataMerge::test_merge_source_count PASSED [ 29%]
tests/test_document_merger.py::TestConflictDetection::test_detect_confidence_conflict PASSED [ 29%]
tests/test_document_merger.py::TestConflictDetection::test_detect_purpose_conflict PASSED [ 29%]
tests/test_document_merger.py::TestConflictDetection::test_detect_topic_divergence PASSED [ 29%]
tests/test_document_merger.py::TestConflictDetection::test_detect_content_contradictions FAILED [ 30%]
tests/test_document_merger.py::TestConflictDetection::test_no_conflict_similar_docs FAILED [ 30%]
tests/test_document_merger.py::TestConflictResolution::test_resolve_conflict_prefer_existing PASSED [ 30%]
tests/test_document_merger.py::TestConflictResolution::test_resolve_conflict_prefer_new PASSED [ 30%]
tests/test_document_merger.py::TestConflictResolution::test_resolve_conflict_manual PASSED [ 30%]
tests/test_document_merger.py::TestConflictResolution::test_invalid_resolution_strategy PASSED [ 31%]
tests/test_document_merger.py::TestMergeReporting::test_merge_report_structure PASSED [ 31%]
tests/test_document_merger.py::TestMergeReporting::test_merge_log_entries PASSED [ 31%]
tests/test_document_merger.py::TestMergeReporting::test_conflict_recording FAILED [ 31%]
tests/test_document_merger.py::TestEdgeCases::test_merge_empty_content PASSED [ 31%]
tests/test_document_merger.py::TestEdgeCases::test_merge_preserves_metadata PASSED [ 32%]
tests/test_document_merger.py::TestEdgeCases::test_merge_updates_timestamp PASSED [ 32%]
tests/test_document_merger.py::TestEdgeCases::test_section_extraction PASSED [ 32%]
tests/test_document_merger.py::TestEdgeCases::test_section_reconstruction PASSED [ 32%]
tests/test_document_merger.py::TestIntegrationScenarios::test_full_merge_workflow FAILED [ 32%]
tests/test_document_merger.py::TestIntegrationScenarios::test_multiple_sequential_merges PASSED [ 33%]
tests/test_document_merger.py::TestIntegrationScenarios::test_merge_with_status_progression PASSED [ 33%]
tests/unit/storage/test_vector_store.py::TestVectorStoreInitialization::test_init_in_memory PASSED [ 33%]
tests/unit/storage/test_vector_store.py::TestVectorStoreInitialization::test_init_persistent FAILED [ 33%]
tests/unit/storage/test_vector_store.py::TestVectorStoreInitialization::test_init_creates_collection PASSED [ 33%]
tests/unit/storage/test_vector_store.py::TestAddDocument::test_add_single_document PASSED [ 33%]
tests/unit/storage/test_vector_store.py::TestAddDocument::test_add_multiple_documents PASSED [ 34%]
tests/unit/storage/test_vector_store.py::TestAddDocument::test_add_document_without_metadata PASSED [ 34%]
tests/unit/storage/test_vector_store.py::TestAddDocument::test_add_document_with_empty_id PASSED [ 34%]
tests/unit/storage/test_vector_store.py::TestAddDocument::test_add_document_with_empty_content PASSED [ 34%]
tests/unit/storage/test_vector_store.py::TestAddDocument::test_add_document_preserves_metadata PASSED [ 34%]
tests/unit/storage/test_vector_store.py::TestSearchSimilar::test_search_basic PASSED [ 35%]
tests/unit/storage/test_vector_store.py::TestSearchSimilar::test_search_with_threshold PASSED [ 35%]
tests/unit/storage/test_vector_store.py::TestSearchSimilar::test_search_returns_high_similarity_first PASSED [ 35%]
tests/unit/storage/test_vector_store.py::TestSearchSimilar::test_search_respects_limit PASSED [ 35%]
tests/unit/storage/test_vector_store.py::TestSearchSimilar::test_search_with_invalid_threshold PASSED [ 35%]
tests/unit/storage/test_vector_store.py::TestSearchSimilar::test_search_with_empty_query PASSED [ 36%]
tests/unit/storage/test_vector_store.py::TestSearchSimilar::test_search_no_results_above_threshold PASSED [ 36%]
tests/unit/storage/test_vector_store.py::TestSearchSimilar::test_search_returns_metadata PASSED [ 36%]
tests/unit/storage/test_vector_store.py::TestUpdateDocument::test_update_document_content PASSED [ 36%]
tests/unit/storage/test_vector_store.py::TestUpdateDocument::test_update_document_metadata PASSED [ 36%]
tests/unit/storage/test_vector_store.py::TestUpdateDocument::test_update_nonexistent_document FAILED [ 37%]
tests/unit/storage/test_vector_store.py::TestUpdateDocument::test_update_with_empty_id PASSED [ 37%]
tests/unit/storage/test_vector_store.py::TestUpdateDocument::test_update_with_empty_content PASSED [ 37%]
tests/unit/storage/test_vector_store.py::TestDeleteDocument::test_delete_single_document PASSED [ 37%]
tests/unit/storage/test_vector_store.py::TestDeleteDocument::test_delete_updates_count FAILED [ 37%]
tests/unit/storage/test_vector_store.py::TestDeleteDocument::test_delete_with_empty_id PASSED [ 38%]
tests/unit/storage/test_vector_store.py::TestDeleteDocument::test_delete_nonexistent_document PASSED [ 38%]
tests/unit/storage/test_vector_store.py::TestGetDocument::test_get_existing_document PASSED [ 38%]
tests/unit/storage/test_vector_store.py::TestGetDocument::test_get_nonexistent_document PASSED [ 38%]
tests/unit/storage/test_vector_store.py::TestGetDocument::test_get_with_empty_id PASSED [ 38%]
tests/unit/storage/test_vector_store.py::TestDeleteAll::test_delete_all_documents FAILED [ 39%]
tests/unit/storage/test_vector_store.py::TestDeleteAll::test_delete_all_empty_store PASSED [ 39%]
tests/unit/storage/test_vector_store.py::TestPersistence::test_persist_to_disk ERROR [ 39%]
tests/unit/storage/test_vector_store.py::TestPersistence::test_persist_idempotent ERROR [ 39%]
tests/unit/storage/test_vector_store.py::TestCollectionStats::test_empty_store_stats PASSED [ 39%]
tests/unit/storage/test_vector_store.py::TestCollectionStats::test_stats_after_adds PASSED [ 40%]
tests/unit/storage/test_vector_store.py::TestCollectionStats::test_stats_after_delete FAILED [ 40%]
tests/unit/storage/test_vector_store.py::TestDuplicateDetection::test_detect_near_duplicate PASSED [ 40%]
tests/unit/storage/test_vector_store.py::TestDuplicateDetection::test_no_false_duplicates PASSED [ 40%]
tests/unit/storage/test_vector_store.py::TestDuplicateDetection::test_duplicate_threshold_edge_case PASSED [ 40%]
tests/unit/test_circuit_breaker.py::TestCircuitBreaker::test_initial_state PASSED [ 41%]
tests/unit/test_circuit_breaker.py::TestCircuitBreaker::test_record_success PASSED [ 41%]
tests/unit/test_circuit_breaker.py::TestCircuitBreaker::test_record_failure PASSED [ 41%]
tests/unit/test_circuit_breaker.py::TestCircuitBreaker::test_open_after_threshold PASSED [ 41%]
tests/unit/test_circuit_breaker.py::TestCircuitBreaker::test_open_blocks_requests PASSED [ 41%]
tests/unit/test_circuit_breaker.py::TestCircuitBreaker::test_half_open_after_timeout PASSED [ 41%]
tests/unit/test_circuit_breaker.py::TestCircuitBreaker::test_close_from_half_open_on_success PASSED [ 42%]
tests/unit/test_circuit_breaker.py::TestCircuitBreaker::test_reopen_from_half_open_on_failure PASSED [ 42%]
tests/unit/test_circuit_breaker.py::TestCircuitBreaker::test_get_status PASSED [ 42%]
tests/unit/test_circuit_breaker.py::TestCircuitBreaker::test_get_status_with_next_attempt PASSED [ 42%]
tests/unit/test_circuit_breaker.py::TestCircuitBreaker::test_reset PASSED [ 42%]
tests/unit/test_circuit_breaker.py::TestCircuitBreaker::test_success_resets_failure_count PASSED [ 43%]
tests/unit/test_circuit_breaker.py::TestCircuitBreaker::test_configurable_thresholds PASSED [ 43%]
tests/unit/test_circuit_breaker.py::TestCircuitBreaker::test_configurable_timeout PASSED [ 43%]
tests/unit/test_circuit_breaker.py::TestCircuitBreaker::test_circuit_breaker_exception PASSED [ 43%]
tests/unit/test_cli.py::TestCLIMain::test_version_option PASSED          [ 43%]
tests/unit/test_cli.py::TestCLIMain::test_help_option PASSED             [ 44%]
tests/unit/test_cli.py::TestCLIMain::test_json_flag PASSED               [ 44%]
tests/unit/test_cli.py::TestInitCommand::test_init_basic FAILED          [ 44%]
tests/unit/test_cli.py::TestInitCommand::test_init_with_profile FAILED   [ 44%]
tests/unit/test_cli.py::TestInitCommand::test_init_already_initialized PASSED [ 44%]
tests/unit/test_cli.py::TestInitCommand::test_init_force PASSED          [ 45%]
tests/unit/test_cli.py::TestStatusCommand::test_status_basic FAILED      [ 45%]
tests/unit/test_cli.py::TestStatusCommand::test_status_json FAILED       [ 45%]
tests/unit/test_cli.py::TestShowCommand::test_show_nonexistent_file PASSED [ 45%]
tests/unit/test_cli.py::TestShowCommand::test_show_metadata_only FAILED  [ 45%]
tests/unit/test_cli.py::TestPlaceholderCommands::test_research_command FAILED [ 46%]
tests/unit/test_cli.py::TestPlaceholderCommands::test_organize_command PASSED [ 46%]
tests/unit/test_cli.py::TestPlaceholderCommands::test_session_commands FAILED [ 46%]
tests/unit/test_cli.py::TestDBCommands::test_db_status FAILED            [ 46%]
tests/unit/test_cli.py::TestGitCommands::test_git_status FAILED          [ 46%]
tests/unit/test_config.py::TestSecureKeyManager::test_set_and_get_api_key PASSED [ 47%]
tests/unit/test_config.py::TestSecureKeyManager::test_get_nonexistent_key PASSED [ 47%]
tests/unit/test_config.py::TestSecureKeyManager::test_delete_api_key PASSED [ 47%]
tests/unit/test_config.py::TestSecureKeyManager::test_delete_nonexistent_key PASSED [ 47%]
tests/unit/test_config.py::TestSecureKeyManager::test_set_empty_provider_raises_error PASSED [ 47%]
tests/unit/test_config.py::TestSecureKeyManager::test_set_empty_key_raises_error PASSED [ 48%]
tests/unit/test_config.py::TestSecureKeyManager::test_verify_key_exists PASSED [ 48%]
tests/unit/test_config.py::TestSecureKeyManager::test_list_providers PASSED [ 48%]
tests/unit/test_config.py::TestSecureKeyManager::test_get_all_keys PASSED [ 48%]
tests/unit/test_config.py::TestSecureKeyManager::test_clear_all_keys PASSED [ 48%]
tests/unit/test_config.py::TestConfigManager::test_singleton_pattern PASSED [ 49%]
tests/unit/test_config.py::TestConfigManager::test_reset_instance PASSED [ 49%]
tests/unit/test_config.py::TestConfigManager::test_load_configuration_default_profile PASSED [ 49%]
tests/unit/test_config.py::TestConfigManager::test_load_configuration_with_profile PASSED [ 49%]
tests/unit/test_config.py::TestConfigManager::test_get_config_before_load_raises_error PASSED [ 49%]
tests/unit/test_config.py::TestConfigManager::test_get_api_key_from_keyring FAILED [ 50%]
tests/unit/test_config.py::TestConfigManager::test_set_api_key_with_persist PASSED [ 50%]
tests/unit/test_config.py::TestConfigManager::test_set_api_key_without_persist PASSED [ 50%]
tests/unit/test_config.py::TestConfigManager::test_set_invalid_provider_raises_error PASSED [ 50%]
tests/unit/test_config.py::TestConfigManager::test_delete_api_key PASSED [ 50%]
tests/unit/test_config.py::TestConfigManager::test_validate_missing_required_keys FAILED [ 50%]
tests/unit/test_config.py::TestConfigManager::test_validate_with_all_keys_set PASSED [ 51%]
tests/unit/test_config.py::TestConfigManager::test_get_config_summary_masked FAILED [ 51%]
tests/unit/test_config.py::TestConfigManager::test_get_config_summary_unmasked PASSED [ 51%]
tests/unit/test_config.py::TestConfigManager::test_set_custom_value PASSED [ 51%]
tests/unit/test_config.py::TestConfigManager::test_reload_configuration PASSED [ 51%]
tests/unit/test_config.py::TestConfigManager::test_profile_property PASSED [ 52%]
tests/unit/test_config.py::TestConfigurationIntegration::test_end_to_end_configuration_flow FAILED [ 52%]
tests/unit/test_config.py::TestConfigurationIntegration::test_keyring_fallback_to_env FAILED [ 52%]
tests/unit/test_config.py::TestConfigurationIntegration::test_keyring_overrides_env FAILED [ 52%]
tests/unit/test_database.py::TestDatabaseManager::test_initialization PASSED [ 52%]
tests/unit/test_database.py::TestDatabaseManager::test_create_tables FAILED [ 53%]
tests/unit/test_database.py::TestDatabaseManager::test_session_scope PASSED [ 53%]
tests/unit/test_database.py::TestDatabaseManager::test_session_scope_rollback PASSED [ 53%]
tests/unit/test_database.py::TestDatabaseManager::test_backup_database PASSED [ 53%]
tests/unit/test_database.py::TestDatabaseManager::test_get_table_stats PASSED [ 53%]
tests/unit/test_deduplication_gate.py::TestSimilarityMatch::test_valid_similarity_match PASSED [ 54%]
tests/unit/test_deduplication_gate.py::TestSimilarityMatch::test_similarity_score_validation PASSED [ 54%]
tests/unit/test_deduplication_gate.py::TestSimilarityMatch::test_similarity_score_boundaries PASSED [ 54%]
tests/unit/test_deduplication_gate.py::TestDeduplicationResult::test_create_action_without_target PASSED [ 54%]
tests/unit/test_deduplication_gate.py::TestDeduplicationResult::test_update_action_requires_target PASSED [ 54%]
tests/unit/test_deduplication_gate.py::TestDeduplicationResult::test_merge_action_requires_target PASSED [ 55%]
tests/unit/test_deduplication_gate.py::TestDeduplicationResult::test_update_action_with_target PASSED [ 55%]
tests/unit/test_deduplication_gate.py::TestDeduplicationResult::test_confidence_validation PASSED [ 55%]
tests/unit/test_deduplication_gate.py::TestDeduplicationGate::test_gate_initialization PASSED [ 55%]
tests/unit/test_deduplication_gate.py::TestDeduplicationGate::test_threshold_validation PASSED [ 55%]
tests/unit/test_deduplication_gate.py::TestDeduplicationGate::test_no_similar_documents_creates_new FAILED [ 56%]
tests/unit/test_deduplication_gate.py::TestDeduplicationGate::test_topic_overlap_calculation PASSED [ 56%]
tests/unit/test_deduplication_gate.py::TestDeduplicationGate::test_content_similarity_calculation PASSED [ 56%]
tests/unit/test_deduplication_gate.py::TestDeduplicationGate::test_overall_similarity_calculation PASSED [ 56%]
tests/unit/test_deduplication_gate.py::TestDeduplicationGate::test_topic_overlap_description FAILED [ 56%]
tests/unit/test_deduplication_gate.py::TestDeduplicationGate::test_word_extraction_for_similarity FAILED [ 57%]
tests/unit/test_deduplication_gate.py::TestDeduplicationGate::test_similarity_threshold_boundaries PASSED [ 57%]
tests/unit/test_deduplication_gate.py::TestDeduplicationGateIntegration::test_empty_database_creates_new FAILED [ 57%]
tests/unit/test_deduplication_gate.py::TestDeduplicationGateIntegration::test_decision_logging FAILED [ 57%]
tests/unit/test_deduplication_gate.py::TestEdgeCases::test_empty_content FAILED [ 57%]
tests/unit/test_deduplication_gate.py::TestEdgeCases::test_empty_topics FAILED [ 58%]
tests/unit/test_deduplication_gate.py::TestEdgeCases::test_very_high_similarity_threshold PASSED [ 58%]
tests/unit/test_deduplication_gate.py::TestEdgeCases::test_question_overlap_with_empty_list PASSED [ 58%]
tests/unit/test_document_finder.py::TestDocumentFinderInitialization::test_init_with_provided_vector_store PASSED [ 58%]
tests/unit/test_document_finder.py::TestDocumentFinderInitialization::test_init_without_vector_store PASSED [ 58%]
tests/unit/test_document_finder.py::TestFindSimilarDocuments::test_find_similar_documents_with_results FAILED [ 58%]
tests/unit/test_document_finder.py::TestFindSimilarDocuments::test_find_similar_documents_empty_query_raises_error PASSED [ 59%]
tests/unit/test_document_finder.py::TestFindSimilarDocuments::test_find_similar_documents_no_results PASSED [ 59%]
tests/unit/test_document_finder.py::TestFindSimilarDocuments::test_find_similar_documents_excludes_ids PASSED [ 59%]
tests/unit/test_document_finder.py::TestFindSimilarDocuments::test_find_similar_documents_respects_limit PASSED [ 59%]
tests/unit/test_document_finder.py::TestFindByTopics::test_find_by_topics_empty_topics_raises_error PASSED [ 59%]
tests/unit/test_document_finder.py::TestFindByTopics::test_find_by_topics_with_results PASSED [ 60%]
tests/unit/test_document_finder.py::TestFindByTopics::test_find_by_topics_respects_confidence_filter PASSED [ 60%]
tests/unit/test_document_finder.py::TestFindByTopics::test_find_by_topics_respects_status_filter PASSED [ 60%]
tests/unit/test_document_finder.py::TestFindByTopics::test_find_by_topics_sorted_by_recency PASSED [ 60%]
tests/unit/test_document_finder.py::TestRankByRelevance::test_rank_by_relevance_empty_list PASSED [ 60%]
tests/unit/test_document_finder.py::TestRankByRelevance::test_rank_by_relevance_applies_recency_boost ERROR [ 61%]
tests/unit/test_document_finder.py::TestRankByRelevance::test_rank_by_relevance_applies_confidence_boost PASSED [ 61%]
tests/unit/test_document_finder.py::TestRankByRelevance::test_rank_by_relevance_applies_length_boost FAILED [ 61%]
tests/unit/test_document_finder.py::TestGetRelatedDocuments::test_get_related_documents_not_found PASSED [ 61%]
tests/unit/test_document_finder.py::TestGetRelatedDocuments::test_get_related_documents_from_relationships PASSED [ 61%]
tests/unit/test_document_finder.py::TestIndexDocument::test_index_document_success PASSED [ 62%]
tests/unit/test_document_finder.py::TestIndexDocument::test_index_document_empty_doc_id_raises_error PASSED [ 62%]
tests/unit/test_document_finder.py::TestDeindexDocument::test_deindex_document_success PASSED [ 62%]
tests/unit/test_document_finder.py::TestDeindexDocument::test_deindex_document_empty_doc_id_raises_error PASSED [ 62%]
tests/unit/test_document_finder.py::TestGetSearchStats::test_get_search_stats_success PASSED [ 62%]
tests/unit/test_document_finder.py::TestContextManager::test_enter_and_exit PASSED [ 63%]
tests/unit/test_git_manager.py::TestGitManagerInitialization::test_init_creates_new_repo PASSED [ 63%]
tests/unit/test_git_manager.py::TestGitManagerInitialization::test_init_opens_existing_repo PASSED [ 63%]
tests/unit/test_git_manager.py::TestGitManagerInitialization::test_init_creates_gitignore PASSED [ 63%]
tests/unit/test_git_manager.py::TestDocumentCommit::test_commit_new_document PASSED [ 63%]
tests/unit/test_git_manager.py::TestDocumentCommit::test_commit_with_relative_path PASSED [ 64%]
tests/unit/test_git_manager.py::TestDocumentCommit::test_commit_modified_document PASSED [ 64%]
tests/unit/test_git_manager.py::TestDocumentCommit::test_commit_no_changes_returns_same_hash PASSED [ 64%]
tests/unit/test_git_manager.py::TestDocumentCommit::test_commit_nonexistent_file_raises_error PASSED [ 64%]
tests/unit/test_git_manager.py::TestDocumentCommit::test_commit_outside_repo_raises_error PASSED [ 64%]
tests/unit/test_git_manager.py::TestDocumentHistory::test_get_history_single_commit PASSED [ 65%]
tests/unit/test_git_manager.py::TestDocumentHistory::test_get_history_multiple_commits PASSED [ 65%]
tests/unit/test_git_manager.py::TestDocumentHistory::test_get_history_with_max_count PASSED [ 65%]
tests/unit/test_git_manager.py::TestDocumentHistory::test_get_history_includes_metadata PASSED [ 65%]
tests/unit/test_git_manager.py::TestDiffOperations::test_diff_between_commits PASSED [ 65%]
tests/unit/test_git_manager.py::TestDiffOperations::test_diff_with_working_tree FAILED [ 66%]
tests/unit/test_git_manager.py::TestFileRestore::test_restore_to_previous_version PASSED [ 66%]
tests/unit/test_git_manager.py::TestFileRestore::test_restore_creates_backup PASSED [ 66%]
tests/unit/test_git_manager.py::TestFileRestore::test_get_file_at_commit PASSED [ 66%]
tests/unit/test_git_manager.py::TestRepositoryStatus::test_get_status_clean_repo PASSED [ 66%]
tests/unit/test_git_manager.py::TestRepositoryStatus::test_get_status_with_untracked PASSED [ 66%]
tests/unit/test_git_manager.py::TestRepositoryStatus::test_get_status_with_modified PASSED [ 67%]
tests/unit/test_git_manager.py::TestRepositoryStatus::test_has_uncommitted_changes PASSED [ 67%]
tests/unit/test_git_manager.py::TestRepositoryStatus::test_has_uncommitted_changes_specific_file PASSED [ 67%]
tests/unit/test_quality_validator.py::TestSourceCredibilityTracker::test_classify_tier1_source PASSED [ 67%]
tests/unit/test_quality_validator.py::TestSourceCredibilityTracker::test_classify_tier1_gov_source PASSED [ 67%]
tests/unit/test_quality_validator.py::TestSourceCredibilityTracker::test_classify_tier1_edu_source PASSED [ 68%]
tests/unit/test_quality_validator.py::TestSourceCredibilityTracker::test_classify_tier2_source PASSED [ 68%]
tests/unit/test_quality_validator.py::TestSourceCredibilityTracker::test_classify_tier2_documentation PASSED [ 68%]
tests/unit/test_quality_validator.py::TestSourceCredibilityTracker::test_classify_tier3_source PASSED [ 68%]
tests/unit/test_quality_validator.py::TestSourceCredibilityTracker::test_classify_tier4_source PASSED [ 68%]
tests/unit/test_quality_validator.py::TestSourceCredibilityTracker::test_calculate_tier1_credibility PASSED [ 69%]
tests/unit/test_quality_validator.py::TestSourceCredibilityTracker::test_calculate_tier2_credibility PASSED [ 69%]
tests/unit/test_quality_validator.py::TestSourceCredibilityTracker::test_calculate_tier3_credibility PASSED [ 69%]
tests/unit/test_quality_validator.py::TestSourceCredibilityTracker::test_calculate_tier4_credibility PASSED [ 69%]
tests/unit/test_quality_validator.py::TestSourceCredibilityTracker::test_verification_boost PASSED [ 69%]
tests/unit/test_quality_validator.py::TestSourceCredibilityTracker::test_track_new_source FAILED [ 70%]
tests/unit/test_quality_validator.py::TestSourceCredibilityTracker::test_track_existing_source FAILED [ 70%]
tests/unit/test_quality_validator.py::TestSourceCredibilityTracker::test_verify_source PASSED [ 70%]
tests/unit/test_quality_validator.py::TestQualityValidatorPreExecution::test_validate_clear_specific_query FAILED [ 70%]
tests/unit/test_quality_validator.py::TestQualityValidatorPreExecution::test_validate_vague_query FAILED [ 70%]
tests/unit/test_quality_validator.py::TestQualityValidatorPreExecution::test_validate_insufficient_budget FAILED [ 71%]
tests/unit/test_quality_validator.py::TestQualityValidatorPreExecution::test_validate_short_query FAILED [ 71%]
tests/unit/test_quality_validator.py::TestQualityValidatorPreExecution::test_permissive_gate_allows_marginal FAILED [ 71%]
tests/unit/test_quality_validator.py::TestQualityValidatorPreExecution::test_strict_gate_rejects_marginal FAILED [ 71%]
tests/unit/test_quality_validator.py::TestQualityValidatorPostExecution::test_validate_good_research FAILED [ 71%]
tests/unit/test_quality_validator.py::TestQualityValidatorPostExecution::test_validate_poor_research_sources FAILED [ 72%]
tests/unit/test_quality_validator.py::TestQualityValidatorPostExecution::test_validate_insufficient_sources FAILED [ 72%]
tests/unit/test_quality_validator.py::TestQualityValidatorPostExecution::test_validate_with_contradictions FAILED [ 72%]
tests/unit/test_quality_validator.py::TestQualityValidatorPostExecution::test_no_sources_yields_zero_credibility FAILED [ 72%]
tests/unit/test_quality_validator.py::TestConfidenceCalculation::test_confidence_breakdown_high_quality FAILED [ 72%]
tests/unit/test_quality_validator.py::TestConfidenceCalculation::test_confidence_breakdown_components_sum FAILED [ 73%]
tests/unit/test_quality_validator.py::TestConfidenceCalculation::test_confidence_empty_sources FAILED [ 73%]
tests/unit/test_quality_validator.py::TestContradictionDetection::test_detect_simple_contradiction FAILED [ 73%]
tests/unit/test_quality_validator.py::TestContradictionDetection::test_detect_no_contradiction PASSED [ 73%]
tests/unit/test_quality_validator.py::TestContradictionDetection::test_detect_multiple_contradictions FAILED [ 73%]
tests/unit/test_quality_validator.py::TestContradictionDetection::test_contradiction_has_severity PASSED [ 74%]
tests/unit/test_quality_validator.py::TestQualityScoringMethods::test_score_query_clarity_high PASSED [ 74%]
tests/unit/test_quality_validator.py::TestQualityScoringMethods::test_score_query_clarity_low PASSED [ 74%]
tests/unit/test_quality_validator.py::TestQualityScoringMethods::test_score_query_specificity_high PASSED [ 74%]
tests/unit/test_quality_validator.py::TestQualityScoringMethods::test_score_query_specificity_low FAILED [ 74%]
tests/unit/test_quality_validator.py::TestQualityScoringMethods::test_score_budget_sufficient PASSED [ 75%]
tests/unit/test_quality_validator.py::TestQualityScoringMethods::test_score_budget_insufficient PASSED [ 75%]
tests/unit/test_quality_validator.py::TestQualityScoringMethods::test_score_coverage_good PASSED [ 75%]
tests/unit/test_quality_validator.py::TestQualityScoringMethods::test_score_coverage_poor PASSED [ 75%]
tests/unit/test_quality_validator.py::TestQualityScoringMethods::test_score_consistency_all_unique PASSED [ 75%]
tests/unit/test_quality_validator.py::TestQualityScoringMethods::test_score_consistency_with_duplicates PASSED [ 75%]
tests/unit/test_quality_validator.py::TestQualityScoringMethods::test_score_recency_recent PASSED [ 76%]
tests/unit/test_quality_validator.py::TestQualityScoringMethods::test_score_recency_old PASSED [ 76%]
tests/unit/test_quality_validator.py::TestQualityScoringMethods::test_score_diversity_all_different PASSED [ 76%]
tests/unit/test_quality_validator.py::TestQualityScoringMethods::test_score_diversity_all_same PASSED [ 76%]
tests/unit/test_research_orchestrator.py::TestResearchOrchestrator::test_initialization FAILED [ 76%]
tests/unit/test_research_orchestrator.py::TestResearchOrchestrator::test_get_max_hops ERROR [ 77%]
tests/unit/test_research_orchestrator.py::TestResearchOrchestrator::test_generate_title ERROR [ 77%]
tests/unit/test_research_orchestrator.py::TestResearchOrchestrator::test_create_research_session ERROR [ 77%]
tests/unit/test_research_orchestrator.py::TestResearchOrchestrator::test_create_research_session_with_cost_override ERROR [ 77%]
tests/unit/test_research_orchestrator.py::TestResearchOrchestrator::test_create_research_session_budgets ERROR [ 77%]
tests/unit/test_research_orchestrator.py::TestResearchExecution::test_execute_research_basic ERROR [ 78%]
tests/unit/test_research_orchestrator.py::TestResearchExecution::test_execute_research_early_stopping ERROR [ 78%]
tests/unit/test_research_orchestrator.py::TestResearchExecution::test_execute_research_budget_limit ERROR [ 78%]
tests/unit/test_research_orchestrator.py::TestResearchExecution::test_execute_research_handles_errors ERROR [ 78%]
tests/unit/test_research_orchestrator.py::TestProgressTracking::test_progress_tracking ERROR [ 78%]
tests/unit/test_research_orchestrator.py::TestDocumentFormatting::test_format_research_findings ERROR [ 79%]
tests/unit/test_research_orchestrator.py::TestDocumentFormatting::test_format_research_findings_with_gaps ERROR [ 79%]
tests/unit/test_research_orchestrator.py::TestAsyncContextManager::test_async_context_manager ERROR [ 79%]
tests/unit/test_sequential_client.py::TestMCPSession::test_initialize FAILED [ 79%]
tests/unit/test_sequential_client.py::TestMCPSession::test_call_tool FAILED [ 79%]
tests/unit/test_sequential_client.py::TestMCPSession::test_error_handling FAILED [ 80%]
tests/unit/test_sequential_client.py::TestSequentialClient::test_start_session FAILED [ 80%]
tests/unit/test_sequential_client.py::TestSequentialClient::test_plan_research FAILED [ 80%]
tests/unit/test_sequential_client.py::TestSequentialClient::test_plan_research_fallback FAILED [ 80%]
tests/unit/test_sequential_client.py::TestSequentialClient::test_generate_hypotheses FAILED [ 80%]
tests/unit/test_sequential_client.py::TestSequentialClient::test_test_hypothesis FAILED [ 81%]
tests/unit/test_sequential_client.py::TestSequentialClient::test_synthesize_findings FAILED [ 81%]
tests/unit/test_sequential_client.py::TestSequentialClient::test_calculate_overall_confidence FAILED [ 81%]
tests/unit/test_sequential_client.py::TestSequentialClient::test_close FAILED [ 81%]
tests/unit/test_sequential_client.py::TestSequentialClient::test_session_not_started_error FAILED [ 81%]
tests/unit/test_sequential_client.py::TestReasoningSchemas::test_hypothesis_str PASSED [ 82%]
tests/unit/test_sequential_client.py::TestReasoningSchemas::test_hypothesis_result_confidence_change FAILED [ 82%]

==================================== ERRORS ====================================
_ ERROR at setup of TestCompleteWorkflow.test_query_to_document_creation_workflow _
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
_ ERROR at setup of TestCompleteWorkflow.test_query_to_deduplication_and_update _
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
_____ ERROR at setup of TestCompleteWorkflow.test_workflow_git_integration _____
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
_ ERROR at setup of TestDeduplicationGateIntegration.test_duplicate_detection_workflow _
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
_ ERROR at setup of TestDeduplicationGateIntegration.test_deduplication_action_execution _
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
_ ERROR at setup of TestSessionPersistence.test_session_creation_and_persistence _
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
_________ ERROR at setup of TestSessionPersistence.test_session_resume _________
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
_____ ERROR at setup of TestSessionPersistence.test_session_state_updates ______
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
___ ERROR at setup of TestSessionPersistence.test_multiple_session_isolation ___
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
__ ERROR at setup of TestCostTrackingAndBudget.test_cost_tracking_in_workflow __
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
_ ERROR at setup of TestQualityValidationAndConfidence.test_confidence_scoring_in_workflow _
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
_ ERROR at setup of TestQualityValidationAndConfidence.test_document_quality_metrics _
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
_ ERROR at setup of TestQualityValidationAndConfidence.test_early_stopping_on_confidence _
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
___ ERROR at setup of TestPerformanceBenchmarks.test_workflow_execution_time ___
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
_ ERROR at setup of TestPerformanceBenchmarks.test_document_store_batch_performance _
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
_ ERROR at setup of TestPerformanceBenchmarks.test_deduplication_performance_scaling _
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
____ ERROR at setup of TestPerformanceBenchmarks.test_session_recovery_time ____
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
___ ERROR at setup of TestIntegrationStress.test_concurrent_research_queries ___
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
_____ ERROR at setup of TestIntegrationStress.test_large_document_handling _____
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
______ ERROR at setup of TestCriticalPaths.test_research_failure_recovery ______
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
__ ERROR at setup of TestCriticalPaths.test_document_update_failure_handling ___
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
_______ ERROR at setup of TestIntegrationHelpers.test_config_validation ________
tests/integration/test_complete_workflow.py:48: in test_config
    return ArisConfig(
.venv/lib/python3.13/site-packages/pydantic_settings/main.py:194: in __init__
    super().__init__(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
E   budget_limit
E     Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
E       For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
_ ERROR at setup of TestCriticalPath_QueryIngestion.test_query_acceptance_and_validation _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_query_acceptance_and_validation' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestCriticalPath_QueryIngestion.test_session_initialization _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_session_initialization' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestCriticalPath_Deduplication.test_duplicate_detection_flow _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_duplicate_detection_flow' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestCriticalPath_Deduplication.test_deduplication_decision_execution _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_deduplication_decision_execution' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestCriticalPath_DocumentStorage.test_document_save_and_retrieve _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1068: in execute
    fixturedef = request._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_document_save_and_retrieve' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestCriticalPath_DocumentStorage.test_document_integrity_after_retrieval _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1068: in execute
    fixturedef = request._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_document_integrity_after_retrieval' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestCriticalPath_DocumentStorage.test_bulk_document_operations _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1068: in execute
    fixturedef = request._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_bulk_document_operations' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestCriticalPath_SessionPersistence.test_session_persistence_cycle _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1068: in execute
    fixturedef = request._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_session_persistence_cycle' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestCriticalPath_SessionPersistence.test_session_state_transitions _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1068: in execute
    fixturedef = request._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_session_state_transitions' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestCriticalPath_ErrorRecovery.test_error_recording_in_session _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1068: in execute
    fixturedef = request._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_error_recording_in_session' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestCriticalPath_ErrorRecovery.test_session_recovery_after_failure _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1068: in execute
    fixturedef = request._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_session_recovery_after_failure' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestDocumentOperationsPerformance.test_single_document_save_performance _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1068: in execute
    fixturedef = request._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_single_document_save_performance' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestDocumentOperationsPerformance.test_bulk_document_save_performance _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1068: in execute
    fixturedef = request._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_bulk_document_save_performance' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestDocumentOperationsPerformance.test_document_retrieval_performance _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1068: in execute
    fixturedef = request._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_document_retrieval_performance' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestDocumentOperationsPerformance.test_document_with_large_content_performance _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1068: in execute
    fixturedef = request._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_document_with_large_content_performance' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestDeduplicationPerformance.test_deduplication_check_performance _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_deduplication_check_performance' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestDeduplicationPerformance.test_deduplication_scaling_performance _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_deduplication_scaling_performance' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestSessionOperationsPerformance.test_session_creation_performance _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1068: in execute
    fixturedef = request._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_session_creation_performance' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestSessionOperationsPerformance.test_session_state_update_performance _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1068: in execute
    fixturedef = request._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_session_state_update_performance' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestSessionOperationsPerformance.test_session_retrieval_performance _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1068: in execute
    fixturedef = request._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_session_retrieval_performance' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestSessionOperationsPerformance.test_bulk_session_operations_performance _
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1068: in execute
    fixturedef = request._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_bulk_session_operations_performance' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
_ ERROR at setup of TestEndToEndWorkflowPerformance.test_workflow_step_timing __
.venv/lib/python3.13/site-packages/_pytest/runner.py:353: in from_call
    result: TResult | None = func()
                             ^^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:245: in <lambda>
    lambda: runtest_hook(item=item, **kwds),
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/logging.py:843: in pytest_runtest_setup
    yield
.venv/lib/python3.13/site-packages/_pytest/capture.py:895: in pytest_runtest_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/runner.py:165: in pytest_runtest_setup
    item.session._setupstate.setup(item)
.venv/lib/python3.13/site-packages/_pytest/runner.py:523: in setup
    col.setup()
.venv/lib/python3.13/site-packages/_pytest/python.py:1723: in setup
    self._request._fillfixtures()
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:707: in _fillfixtures
    item.funcargs[argname] = self.getfixturevalue(argname)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:539: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:627: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1110: in execute
    result: FixtureValue = ihook.pytest_fixture_setup(
.venv/lib/python3.13/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:53: in run_old_style_hookwrapper
    return result.get_result()
           ^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/pluggy/_callers.py:38: in run_old_style_hookwrapper
    res = yield
          ^^^^^
.venv/lib/python3.13/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
            ^^^^^
.venv/lib/python3.13/site-packages/_pytest/fixtures.py:1188: in pytest_fixture_setup
    warnings.warn(
E   pytest.PytestRemovedIn9Warning: 'test_workflow_step_timing' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
E   See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
____________ ERROR at setup of TestPersistence.test_persist_to_disk ____________
src/aris/storage/vector_store.py:52: in __init__
    self.client = chromadb.Client(settings)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/chromadb/__init__.py:430: in Client
    return ClientCreator(tenant=tenant, database=database, settings=settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/chromadb/api/client.py:66: in __init__
    super().__init__(settings=settings)
.venv/lib/python3.13/site-packages/chromadb/api/shared_system_client.py:19: in __init__
    SharedSystemClient._create_system_if_not_exists(self._identifier, settings)
.venv/lib/python3.13/site-packages/chromadb/api/shared_system_client.py:38: in _create_system_if_not_exists
    raise ValueError(
E   ValueError: An instance of Chroma already exists for ephemeral with different settings

The above exception was the direct cause of the following exception:
tests/unit/storage/test_vector_store.py:19: in persistent_vector_store
    return VectorStore(persist_dir=tmp_path / "vector_store")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src/aris/storage/vector_store.py:65: in __init__
    raise VectorStoreError(f"Failed to initialize vector store: {e}") from e
E   aris.storage.vector_store.VectorStoreError: Failed to initialize vector store: An instance of Chroma already exists for ephemeral with different settings
__________ ERROR at setup of TestPersistence.test_persist_idempotent ___________
src/aris/storage/vector_store.py:52: in __init__
    self.client = chromadb.Client(settings)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/chromadb/__init__.py:430: in Client
    return ClientCreator(tenant=tenant, database=database, settings=settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/chromadb/api/client.py:66: in __init__
    super().__init__(settings=settings)
.venv/lib/python3.13/site-packages/chromadb/api/shared_system_client.py:19: in __init__
    SharedSystemClient._create_system_if_not_exists(self._identifier, settings)
.venv/lib/python3.13/site-packages/chromadb/api/shared_system_client.py:38: in _create_system_if_not_exists
    raise ValueError(
E   ValueError: An instance of Chroma already exists for ephemeral with different settings

The above exception was the direct cause of the following exception:
tests/unit/storage/test_vector_store.py:19: in persistent_vector_store
    return VectorStore(persist_dir=tmp_path / "vector_store")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src/aris/storage/vector_store.py:65: in __init__
    raise VectorStoreError(f"Failed to initialize vector store: {e}") from e
E   aris.storage.vector_store.VectorStoreError: Failed to initialize vector store: An instance of Chroma already exists for ephemeral with different settings
_ ERROR at setup of TestRankByRelevance.test_rank_by_relevance_applies_recency_boost _
tests/unit/test_document_finder.py:43: in sample_document
    status=DocumentStatus.PUBLISHED,
           ^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: type object 'DocumentStatus' has no attribute 'PUBLISHED'
_________ ERROR at setup of TestResearchOrchestrator.test_get_max_hops _________
tests/unit/test_research_orchestrator.py:50: in orchestrator
    patch("aris.core.research_orchestrator.DocumentStore", return_value=mock_document_store), \
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1467: in get_original
    raise AttributeError(
E   AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
________ ERROR at setup of TestResearchOrchestrator.test_generate_title ________
tests/unit/test_research_orchestrator.py:50: in orchestrator
    patch("aris.core.research_orchestrator.DocumentStore", return_value=mock_document_store), \
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1467: in get_original
    raise AttributeError(
E   AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
___ ERROR at setup of TestResearchOrchestrator.test_create_research_session ____
tests/unit/test_research_orchestrator.py:50: in orchestrator
    patch("aris.core.research_orchestrator.DocumentStore", return_value=mock_document_store), \
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1467: in get_original
    raise AttributeError(
E   AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
_ ERROR at setup of TestResearchOrchestrator.test_create_research_session_with_cost_override _
tests/unit/test_research_orchestrator.py:50: in orchestrator
    patch("aris.core.research_orchestrator.DocumentStore", return_value=mock_document_store), \
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1467: in get_original
    raise AttributeError(
E   AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
_ ERROR at setup of TestResearchOrchestrator.test_create_research_session_budgets _
tests/unit/test_research_orchestrator.py:50: in orchestrator
    patch("aris.core.research_orchestrator.DocumentStore", return_value=mock_document_store), \
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1467: in get_original
    raise AttributeError(
E   AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
_____ ERROR at setup of TestResearchExecution.test_execute_research_basic ______
tests/unit/test_research_orchestrator.py:50: in orchestrator
    patch("aris.core.research_orchestrator.DocumentStore", return_value=mock_document_store), \
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1467: in get_original
    raise AttributeError(
E   AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
_ ERROR at setup of TestResearchExecution.test_execute_research_early_stopping _
tests/unit/test_research_orchestrator.py:50: in orchestrator
    patch("aris.core.research_orchestrator.DocumentStore", return_value=mock_document_store), \
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1467: in get_original
    raise AttributeError(
E   AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
__ ERROR at setup of TestResearchExecution.test_execute_research_budget_limit __
tests/unit/test_research_orchestrator.py:50: in orchestrator
    patch("aris.core.research_orchestrator.DocumentStore", return_value=mock_document_store), \
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1467: in get_original
    raise AttributeError(
E   AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
_ ERROR at setup of TestResearchExecution.test_execute_research_handles_errors _
tests/unit/test_research_orchestrator.py:50: in orchestrator
    patch("aris.core.research_orchestrator.DocumentStore", return_value=mock_document_store), \
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1467: in get_original
    raise AttributeError(
E   AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
________ ERROR at setup of TestProgressTracking.test_progress_tracking _________
tests/unit/test_research_orchestrator.py:50: in orchestrator
    patch("aris.core.research_orchestrator.DocumentStore", return_value=mock_document_store), \
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1467: in get_original
    raise AttributeError(
E   AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
____ ERROR at setup of TestDocumentFormatting.test_format_research_findings ____
tests/unit/test_research_orchestrator.py:50: in orchestrator
    patch("aris.core.research_orchestrator.DocumentStore", return_value=mock_document_store), \
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1467: in get_original
    raise AttributeError(
E   AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
_ ERROR at setup of TestDocumentFormatting.test_format_research_findings_with_gaps _
tests/unit/test_research_orchestrator.py:50: in orchestrator
    patch("aris.core.research_orchestrator.DocumentStore", return_value=mock_document_store), \
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1467: in get_original
    raise AttributeError(
E   AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
_____ ERROR at setup of TestAsyncContextManager.test_async_context_manager _____
tests/unit/test_research_orchestrator.py:50: in orchestrator
    patch("aris.core.research_orchestrator.DocumentStore", return_value=mock_document_store), \
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1467: in get_original
    raise AttributeError(
E   AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
=================================== FAILURES ===================================
_____________ TestCLIIntegration.test_full_initialization_workflow _____________
tests/integration/test_cli_integration.py:53: in test_full_initialization_workflow
    assert result.exit_code == 0
E   assert 1 == 0
E    +  where 1 = <Result SystemExit(1)>.exit_code
__________________ TestCLIIntegration.test_status_after_init ___________________
tests/integration/test_cli_integration.py:84: in test_status_after_init
    assert result.exit_code == 0
E   assert 1 == 0
E    +  where 1 = <Result SystemExit(1)>.exit_code
___________________ TestCLIIntegration.test_json_output_mode ___________________
tests/integration/test_cli_integration.py:99: in test_json_output_mode
    assert result.exit_code == 0
E   assert 1 == 0
E    +  where 1 = <Result SystemExit(1)>.exit_code
_________________ TestCLIIntegration.test_db_commands_workflow _________________
tests/integration/test_cli_integration.py:119: in test_db_commands_workflow
    assert result.exit_code == 0
E   assert 1 == 0
E    +  where 1 = <Result SystemExit(1)>.exit_code
___________ TestCLIIntegration.test_placeholder_commands_accessible ____________
tests/integration/test_cli_integration.py:139: in test_placeholder_commands_accessible
    assert result.exit_code == 0
E   assert 1 == 0
E    +  where 1 = <Result SystemExit(1)>.exit_code
___________________ TestCLIOutputFormats.test_verbose_output ___________________
tests/integration/test_cli_integration.py:230: in test_verbose_output
    assert result_normal.exit_code == 0
E   assert 1 == 0
E    +  where 1 = <Result SystemExit(1)>.exit_code
____________ TestCostTrackingAndBudget.test_cost_operation_tracking ____________
tests/integration/test_complete_workflow.py:489: in test_cost_operation_tracking
    tracker.track_operation("search", cost=0.01)
    ^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'CostTracker' object has no attribute 'track_operation'. Did you mean: 'record_operation'?
___________ TestCostTrackingAndBudget.test_budget_limit_enforcement ____________
tests/integration/test_complete_workflow.py:501: in test_budget_limit_enforcement
    tracker = CostTracker(budget_limit=0.05)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   TypeError: CostTracker.__init__() got an unexpected keyword argument 'budget_limit'
____________ TestCriticalPaths.test_git_operation_failure_handling _____________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
__________ TestCriticalPath_CostTracking.test_cost_tracking_accuracy ___________
tests/integration/test_critical_paths.py:374: in test_cost_tracking_accuracy
    tracker = CostTracker(budget_limit=1.0)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   TypeError: CostTracker.__init__() got an unexpected keyword argument 'budget_limit'
_________ TestCriticalPath_CostTracking.test_budget_limit_enforcement __________
tests/integration/test_critical_paths.py:394: in test_budget_limit_enforcement
    tracker = CostTracker(budget_limit=0.50)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   TypeError: CostTracker.__init__() got an unexpected keyword argument 'budget_limit'
__________ TestCriticalPath_QualityValidation.test_confidence_scoring __________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
____ TestCriticalPath_QualityValidation.test_quality_threshold_enforcement _____
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
___________________ TestDocumentSave.test_save_new_document ____________________
tests/integration/test_document_store.py:75: in test_save_new_document
    saved = document_store.save_document(sample_document, operation="create")
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
_________________ TestDocumentSave.test_save_creates_directory _________________
tests/integration/test_document_store.py:87: in test_save_creates_directory
    document_store.save_document(sample_document, operation="create")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
________________ TestDocumentSave.test_save_creates_git_commit _________________
tests/integration/test_document_store.py:95: in test_save_creates_git_commit
    document_store.save_document(sample_document, operation="create")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
____________ TestDocumentSave.test_save_with_custom_commit_message _____________
tests/integration/test_document_store.py:105: in test_save_with_custom_commit_message
    document_store.save_document(
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
_________________ TestDocumentSave.test_save_update_operation __________________
tests/integration/test_document_store.py:118: in test_save_update_operation
    document_store.save_document(sample_document, operation="create")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
________________ TestDocumentSave.test_save_preserves_metadata _________________
tests/integration/test_document_store.py:134: in test_save_preserves_metadata
    document_store.save_document(sample_document, operation="create")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
_________________ TestDocumentLoad.test_load_existing_document _________________
tests/integration/test_document_store.py:151: in test_load_existing_document
    document_store.save_document(sample_document, operation="create")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
_________ TestDocumentLoad.test_load_nonexistent_document_raises_error _________
tests/integration/test_document_store.py:165: in test_load_nonexistent_document_raises_error
    document_store.load_document(fake_path)
src/aris/storage/document_store.py:138: in load_document
    raise DocumentStoreError(f"Document not found: {file_path}")
E   aris.storage.document_store.DocumentStoreError: Document not found: /tmp/tmpldrcq3s2/research/nonexistent.md

During handling of the above exception, another exception occurred:
tests/integration/test_document_store.py:164: in test_load_nonexistent_document_raises_error
    with pytest.raises(DocumentStoreError, match="does not exist"):
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AssertionError: Regex pattern did not match.
E     Expected regex: 'does not exist'
E     Actual message: 'Document not found: /tmp/tmpldrcq3s2/research/nonexistent.md'
_______________ TestDocumentLoad.test_load_document_from_commit ________________
tests/integration/test_document_store.py:170: in test_load_document_from_commit
    document_store.save_document(sample_document, operation="create")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
_____________ TestVersionHistory.test_get_versions_single_version ______________
tests/integration/test_document_store.py:196: in test_get_versions_single_version
    document_store.save_document(sample_document, operation="create")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
____________ TestVersionHistory.test_get_versions_multiple_versions ____________
tests/integration/test_document_store.py:209: in test_get_versions_multiple_versions
    document_store.save_document(sample_document, operation="update")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
_______________ TestVersionHistory.test_get_versions_with_limit ________________
tests/integration/test_document_store.py:223: in test_get_versions_with_limit
    document_store.save_document(sample_document, operation="update")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
________________ TestDiffOperations.test_diff_between_versions _________________
tests/integration/test_document_store.py:241: in test_diff_between_versions
    document_store.save_document(sample_document, operation="create")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
__________________ TestDiffOperations.test_diff_with_current ___________________
tests/integration/test_document_store.py:266: in test_diff_with_current
    document_store.save_document(sample_document, operation="create")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
____________ TestRestoreOperations.test_restore_to_previous_version ____________
tests/integration/test_document_store.py:287: in test_restore_to_previous_version
    document_store.save_document(sample_document, operation="create")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
______________ TestRestoreOperations.test_restore_creates_backup _______________
tests/integration/test_document_store.py:310: in test_restore_creates_backup
    document_store.save_document(sample_document, operation="create")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
__________________ TestRepositoryStatus.test_get_status_clean __________________
tests/integration/test_document_store.py:339: in test_get_status_clean
    document_store.save_document(sample_document, operation="create")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
____________ TestRepositoryStatus.test_get_status_with_uncommitted _____________
tests/integration/test_document_store.py:351: in test_get_status_with_uncommitted
    document_store.save_document(sample_document, operation="create")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
______________ TestRepositoryStatus.test_has_uncommitted_changes _______________
tests/integration/test_document_store.py:365: in test_has_uncommitted_changes
    document_store.save_document(sample_document, operation="create")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
___________________ TestDocumentList.test_list_all_documents ___________________
tests/integration/test_document_store.py:393: in test_list_all_documents
    document_store.save_document(doc, operation="create")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
____________ TestDocumentList.test_list_documents_with_topic_filter ____________
tests/integration/test_document_store.py:415: in test_list_documents_with_topic_filter
    document_store.save_document(doc, operation="create")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
___________ TestDocumentList.test_list_documents_with_status_filter ____________
tests/integration/test_document_store.py:438: in test_list_documents_with_status_filter
    document_store.save_document(doc, operation="create")
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
_________________ TestEndToEndResearch.test_complete_workflow __________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_________________ TestEndToEndResearch.test_multi_hop_workflow _________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
___________ TestEndToEndResearch.test_progress_tracking_integration ____________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
___________ TestEndToEndResearch.test_document_creation_integration ____________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
___________________ TestEndToEndResearch.test_error_recovery ___________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_________________ TestEndToEndResearch.test_budget_enforcement _________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
___ TestReasoningEngineIntegration.test_reasoning_engine_hypothesis_workflow ___
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_____ TestReasoningEngineIntegration.test_confidence_based_early_stopping ______
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
______________ TestAsyncContextManager.test_context_manager_usage ______________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_____ TestCostTrackingPerformance.test_cost_operation_tracking_performance _____
tests/integration/test_performance_benchmarks.py:333: in test_cost_operation_tracking_performance
    tracker.track_operation("search", cost=0.01)
    ^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'CostTracker' object has no attribute 'track_operation'. Did you mean: 'record_operation'?
_____ TestCostTrackingPerformance.test_cost_summary_generation_performance _____
tests/integration/test_performance_benchmarks.py:348: in test_cost_summary_generation_performance
    tracker.track_operation("search", cost=0.01)
    ^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'CostTracker' object has no attribute 'track_operation'. Did you mean: 'record_operation'?
________ TestProgressTrackingPerformance.test_hop_recording_performance ________
tests/integration/test_performance_benchmarks.py:376: in test_hop_recording_performance
    tracker.record_hop(
    ^^^^^^^^^^^^^^^^^^
E   AttributeError: 'ProgressTracker' object has no attribute 'record_hop'
______ TestProgressTrackingPerformance.test_stats_computation_performance ______
tests/integration/test_performance_benchmarks.py:393: in test_stats_computation_performance
    tracker.record_hop(
    ^^^^^^^^^^^^^^^^^^
E   AttributeError: 'ProgressTracker' object has no attribute 'record_hop'
____________________ TestReasoningEngine.test_analyze_query ____________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
________________ TestReasoningEngine.test_execute_research_hop _________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
____________ TestReasoningEngine.test_multi_hop_research_early_stop ____________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_____________ TestReasoningEngine.test_multi_hop_research_max_hops _____________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
___________ TestReasoningEngine.test_gather_evidence_error_handling ____________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
__________________ TestReasoningEngine.test_refine_hypothesis __________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_____________ TestReasoningEngine.test_generate_follow_up_queries ______________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
____________________ TestReasoningEngine.test_cost_tracking ____________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_________________ TestReasoningEngine.test_context_management __________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
________________ TestReasoningEngine.test_async_context_manager ________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
__________________ TestRepositories.test_document_repository ___________________
tests/integration/test_repositories.py:104: in test_document_repository
    retrieved = doc_repo.get_by_id(doc.id)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
src/aris/storage/repositories.py:190: in get_by_id
    ).scalar_one_or_none()
      ^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/sqlalchemy/engine/result.py:1492: in scalar_one_or_none
    return self._only_one_row(
.venv/lib/python3.13/site-packages/sqlalchemy/engine/result.py:784: in _only_one_row
    existing_row_hash = strategy(row) if strategy else row
                        ^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/sqlalchemy/orm/loading.py:286: in require_unique
    raise sa_exc.InvalidRequestError(
E   sqlalchemy.exc.InvalidRequestError: The unique() method must be invoked on this Result, as it contains results that include joined eager loads against collections
______________ TestRepositories.test_research_session_repository _______________
tests/integration/test_repositories.py:217: in test_research_session_repository
    retrieved = session_repo.get_by_id(research_session.id)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src/aris/storage/repositories.py:587: in get_by_id
    ).scalar_one_or_none()
      ^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/sqlalchemy/engine/result.py:1492: in scalar_one_or_none
    return self._only_one_row(
.venv/lib/python3.13/site-packages/sqlalchemy/engine/result.py:784: in _only_one_row
    existing_row_hash = strategy(row) if strategy else row
                        ^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/sqlalchemy/orm/loading.py:286: in require_unique
    raise sa_exc.InvalidRequestError(
E   sqlalchemy.exc.InvalidRequestError: The unique() method must be invoked on this Result, as it contains results that include joined eager loads against collections
________________ TestCostBreakdown.test_cost_breakdown_creation ________________
tests/test_cost_manager.py:42: in test_cost_breakdown_creation
    assert breakdown.total_cost == 0.06
E   assert 0.060000000000000005 == 0.06
E    +  where 0.060000000000000005 = CostBreakdown(tavily_cost=0.05, llm_tokens=1000, llm_cost=0.01, total_cost=0.060000000000000005, timestamp=datetime.datetime(2025, 11, 13, 17, 25, 29, 487914)).total_cost
____________ TestCostManager.test_track_hop_cost_with_calculations _____________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
______________ TestCostManager.test_track_hop_cost_with_overrides ______________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_______________ TestCostManager.test_budget_threshold_75_percent _______________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_______________ TestCostManager.test_budget_threshold_90_percent _______________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
________________ TestCostManager.test_budget_threshold_critical ________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
___________ TestCostManager.test_can_perform_operation_within_budget ___________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
__________ TestCostManager.test_can_perform_operation_exceeds_budget ___________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
___________ TestCostIntegration.test_multiple_hops_cost_accumulation ___________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
______________ TestCostIntegration.test_export_cost_history_json _______________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_______________ TestMergeStrategies.test_invalid_merge_strategy ________________
tests/test_document_merger.py:114: in test_invalid_merge_strategy
    merger.merge_documents(
src/aris/core/document_merger.py:139: in merge_documents
    f"Starting merge: strategy={strategy.value}, "
                                ^^^^^^^^^^^^^^
E   AttributeError: 'str' object has no attribute 'value'
____________________ TestMetadataMerge.test_merge_questions ____________________
tests/test_document_merger.py:150: in test_merge_questions
    assert set(result.metadata.questions_answered) == expected_questions
E   AssertionError: assert set() == {'What is deep learning?', 'How does ML work?', 'What is AI?'}
E     
E     Extra items in the right set:
E     'What is deep learning?'
E     'How does ML work?'
E     'What is AI?'
E     
E     Full diff:
E     + set()
E     - {
E     -     'How does ML work?',
E     -     'What is AI?',
E     -     'What is deep learning?',
E     - }
------------------------------ Captured log call -------------------------------
WARNING  aris.core.document_merger:document_merger.py:274 Metadata conflict: Conflict(metadata, purpose, severity=medium)
___________ TestConflictDetection.test_detect_content_contradictions ___________
tests/test_document_merger.py:240: in test_detect_content_contradictions
    metadata=DocumentMetadata(title="Test"),
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for DocumentMetadata
E   purpose
E     Field required [type=missing, input_value={'title': 'Test'}, input_type=dict]
E       For further information visit https://errors.pydantic.dev/2.12/v/missing
_____________ TestConflictDetection.test_no_conflict_similar_docs ______________
tests/test_document_merger.py:259: in test_no_conflict_similar_docs
    metadata=DocumentMetadata(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for DocumentMetadata
E   purpose
E     Field required [type=missing, input_value={'title': 'Research', 'to...I'], 'confidence': 0.75}, input_type=dict]
E       For further information visit https://errors.pydantic.dev/2.12/v/missing
__________________ TestMergeReporting.test_conflict_recording __________________
tests/test_document_merger.py:371: in test_conflict_recording
    metadata=DocumentMetadata(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for DocumentMetadata
E   purpose
E     Field required [type=missing, input_value={'title': 'Test', 'confidence': 0.75}, input_type=dict]
E       For further information visit https://errors.pydantic.dev/2.12/v/missing
______________ TestIntegrationScenarios.test_full_merge_workflow _______________
tests/test_document_merger.py:489: in test_full_merge_workflow
    assert report["strategy"] == "integrate"
           ^^^^^^^^^^^^^^^^^^
E   KeyError: 'strategy'
------------------------------ Captured log call -------------------------------
WARNING  aris.core.document_merger:document_merger.py:274 Metadata conflict: Conflict(metadata, purpose, severity=medium)
______________ TestVectorStoreInitialization.test_init_persistent ______________
src/aris/storage/vector_store.py:52: in __init__
    self.client = chromadb.Client(settings)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/chromadb/__init__.py:430: in Client
    return ClientCreator(tenant=tenant, database=database, settings=settings)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.venv/lib/python3.13/site-packages/chromadb/api/client.py:66: in __init__
    super().__init__(settings=settings)
.venv/lib/python3.13/site-packages/chromadb/api/shared_system_client.py:19: in __init__
    SharedSystemClient._create_system_if_not_exists(self._identifier, settings)
.venv/lib/python3.13/site-packages/chromadb/api/shared_system_client.py:38: in _create_system_if_not_exists
    raise ValueError(
E   ValueError: An instance of Chroma already exists for ephemeral with different settings

The above exception was the direct cause of the following exception:
tests/unit/storage/test_vector_store.py:35: in test_init_persistent
    store = VectorStore(persist_dir=persist_dir)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src/aris/storage/vector_store.py:65: in __init__
    raise VectorStoreError(f"Failed to initialize vector store: {e}") from e
E   aris.storage.vector_store.VectorStoreError: Failed to initialize vector store: An instance of Chroma already exists for ephemeral with different settings
_____________ TestUpdateDocument.test_update_nonexistent_document ______________
tests/unit/storage/test_vector_store.py:270: in test_update_nonexistent_document
    assert retrieved is not None
E   assert None is not None
_________________ TestDeleteDocument.test_delete_updates_count _________________
tests/unit/storage/test_vector_store.py:303: in test_delete_updates_count
    assert stats_before["total_documents"] == 2
E   assert 14 == 2
___________________ TestDeleteAll.test_delete_all_documents ____________________
tests/unit/storage/test_vector_store.py:359: in test_delete_all_documents
    assert stats_before["total_documents"] == 5
E   assert 18 == 5
_________________ TestCollectionStats.test_stats_after_delete __________________
tests/unit/storage/test_vector_store.py:420: in test_stats_after_delete
    assert stats["total_documents"] == 1
E   assert 2 == 1
_______________________ TestInitCommand.test_init_basic ________________________
tests/unit/test_cli.py:79: in test_init_basic
    assert "Initialized ARIS project" in result.output
E   AssertionError: assert 'Initialized ARIS project' in '\u26a0\ufe0f  Warning: Project already initialized\n'
E    +  where '\u26a0\ufe0f  Warning: Project already initialized\n' = <Result okay>.output
____________________ TestInitCommand.test_init_with_profile ____________________
tests/unit/test_cli.py:94: in test_init_with_profile
    assert "production" in result.output.lower()
E   AssertionError: assert 'production' in '\u26a0\ufe0f  warning: project already initialized\n'
E    +  where '\u26a0\ufe0f  warning: project already initialized\n' = <built-in method lower of str object at 0x7f05a5400490>()
E    +    where <built-in method lower of str object at 0x7f05a5400490> = '\u26a0\ufe0f  Warning: Project already initialized\n'.lower
E    +      where '\u26a0\ufe0f  Warning: Project already initialized\n' = <Result okay>.output
_____________________ TestStatusCommand.test_status_basic ______________________
tests/unit/test_cli.py:129: in test_status_basic
    assert result.exit_code == 0
E   assert 1 == 0
E    +  where 1 = <Result SystemExit(1)>.exit_code
______________________ TestStatusCommand.test_status_json ______________________
tests/unit/test_cli.py:143: in test_status_json
    assert result.exit_code == 0
E   assert 1 == 0
E    +  where 1 = <Result SystemExit(1)>.exit_code
___________________ TestShowCommand.test_show_metadata_only ____________________
tests/unit/test_cli.py:178: in test_show_metadata_only
    assert result.exit_code == 0
E   assert 1 == 0
E    +  where 1 = <Result SystemExit(1)>.exit_code
________________ TestPlaceholderCommands.test_research_command _________________
tests/unit/test_cli.py:188: in test_research_command
    assert result.exit_code == 0
E   assert 1 == 0
E    +  where 1 = <Result SystemExit(1)>.exit_code
________________ TestPlaceholderCommands.test_session_commands _________________
tests/unit/test_cli.py:200: in test_session_commands
    assert result.exit_code == 0
E   assert 2 == 0
E    +  where 2 = <Result SystemExit(2)>.exit_code
________________________ TestDBCommands.test_db_status _________________________
tests/unit/test_cli.py:221: in test_db_status
    assert result.exit_code == 0
E   assert 1 == 0
E    +  where 1 = <Result SystemExit(1)>.exit_code
_______________________ TestGitCommands.test_git_status ________________________
tests/unit/test_cli.py:233: in test_git_status
    assert result.exit_code == 0
E   assert 1 == 0
E    +  where 1 = <Result SystemExit(1)>.exit_code
_______________ TestConfigManager.test_get_api_key_from_keyring ________________
tests/unit/test_config.py:230: in test_get_api_key_from_keyring
    assert key == "keyring_key_123"
E   AssertionError: assert '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' == 'keyring_key_123'
E     
E     - keyring_key_123
E     + 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
____________ TestConfigManager.test_validate_missing_required_keys _____________
tests/unit/test_config.py:306: in test_validate_missing_required_keys
    assert validation["valid"] is False
E   assert True is False
_______________ TestConfigManager.test_get_config_summary_masked _______________
tests/unit/test_config.py:348: in test_get_config_summary_masked
    assert summary["api_keys"]["tavily"] == "Not set"
E   AssertionError: assert 'tvly-dev...HKjC' == 'Not set'
E     
E     - Not set
E     + tvly-dev...HKjC
_______ TestConfigurationIntegration.test_end_to_end_configuration_flow ________
tests/unit/test_config.py:433: in test_end_to_end_configuration_flow
    assert not validation["valid"]
E   assert not True
__________ TestConfigurationIntegration.test_keyring_fallback_to_env ___________
tests/unit/test_config.py:464: in test_keyring_fallback_to_env
    assert key == "env_key_123"
E   AssertionError: assert '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' == 'env_key_123'
E     
E     - env_key_123
E     + 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
___________ TestConfigurationIntegration.test_keyring_overrides_env ____________
tests/unit/test_config.py:481: in test_keyring_overrides_env
    assert key == "keyring_key"
E   AssertionError: assert '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' == 'keyring_key'
E     
E     - keyring_key
E     + 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
____________________ TestDatabaseManager.test_create_tables ____________________
tests/unit/test_database.py:51: in test_create_tables
    assert set(stats.keys()) == expected_tables
E   AssertionError: assert {'quality_metrics', 'document_sources', 'topics', 'research_sessions', 'conflicts', 'sources', 'contradiction_detection', 'relationships', 'source_credibility', 'documents', 'validation_rule_history', 'research_hops'} == {'document_sources', 'topics', 'conflicts', 'research_sessions', 'sources', 'relationships', 'documents', 'research_hops'}
E     
E     Extra items in the left set:
E     'quality_metrics'
E     'source_credibility'
E     'validation_rule_history'
E     'contradiction_detection'
E     
E     Full diff:
E       {
E           'conflicts',
E     +     'contradiction_detection',
E           'document_sources',
E           'documents',
E     +     'quality_metrics',
E           'relationships',
E           'research_hops',
E           'research_sessions',
E     +     'source_credibility',
E           'sources',
E           'topics',
E     +     'validation_rule_history',
E       }
_________ TestDeduplicationGate.test_no_similar_documents_creates_new __________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_____________ TestDeduplicationGate.test_topic_overlap_description _____________
tests/unit/test_deduplication_gate.py:303: in test_topic_overlap_description
    assert "AI" in desc
E   AssertionError: assert 'AI' in 'ai'
__________ TestDeduplicationGate.test_word_extraction_for_similarity ___________
tests/unit/test_deduplication_gate.py:317: in test_word_extraction_for_similarity
    assert score > 0.5
E   assert 0.5 > 0.5
_______ TestDeduplicationGateIntegration.test_empty_database_creates_new _______
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
____________ TestDeduplicationGateIntegration.test_decision_logging ____________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_______________________ TestEdgeCases.test_empty_content _______________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_______________________ TestEdgeCases.test_empty_topics ________________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
______ TestFindSimilarDocuments.test_find_similar_documents_with_results _______
tests/unit/test_document_finder.py:129: in test_find_similar_documents_with_results
    status=DocumentStatus.PUBLISHED,
           ^^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: type object 'DocumentStatus' has no attribute 'PUBLISHED'
_______ TestRankByRelevance.test_rank_by_relevance_applies_length_boost ________
tests/unit/test_document_finder.py:484: in test_rank_by_relevance_applies_length_boost
    assert len(ranked[0][0].content) > len(ranked[1][0].content)
E   AssertionError: assert 13 > 1000
E    +  where 13 = len('short content')
E    +    where 'short content' = Document(metadata=DocumentMetadata(id=UUID('76adc506-0c5d-47ec-99dc-426fb2885e7c'), title='Short', purpose='test', topics=[], questions_answered=[], status=<DocumentStatus.DRAFT: 'draft'>, created_at=datetime.datetime(2025, 11, 13, 17, 25, 44, 361857), updated_at=datetime.datetime(2025, 11, 13, 17, 25, 44, 361841), last_validated=None, confidence=0.8, source_count=0, related_docs=[], supersedes=None, superseded_by=None), content='short content', file_path=PosixPath('research/test/short.md'), embedding_id=None).content
E    +  and   1000 = len('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')
E    +    where 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx' = Document(metadata=DocumentMetadata(id=UUID('eb221bc9-46b2-4fa7-80ca-ac2bb4bc1d00'), title='Long', purpose='test', topics=[], questions_answered=[], status=<DocumentStatus.DRAFT: 'draft'>, created_at=datetime.datetime(2025, 11, 13, 17, 25, 44, 361876), updated_at=datetime.datetime(2025, 11, 13, 17, 25, 44, 361870), last_validated=None, confidence=0.8, source_count=0, related_docs=[], supersedes=None, superseded_by=None), content='xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', file_path=PosixPath('research/test/long.md'), embedding_id=None).content
________________ TestDiffOperations.test_diff_with_working_tree ________________
tests/unit/test_git_manager.py:247: in test_diff_with_working_tree
    assert "-Committed" in diff
E   AssertionError: assert '-Committed' in 'diff --git a/test.md b/test.md\nindex afa3ae0..dcab6f5 100644\n--- a/test.md\n+++ b/test.md\n@@ -1 +1 @@\n-# Committed\n\\ No newline at end of file\n+# Modified\n\\ No newline at end of file'
______________ TestSourceCredibilityTracker.test_track_new_source ______________
tests/unit/test_quality_validator.py:112: in test_track_new_source
    assert record.times_cited == 1
E   AssertionError: assert 0 == 1
E    +  where 0 = SourceCredibilityRecord(source_id='d0ccc056-0978-46ad-bf38-4bec708053ce', domain='example.edu', url='https://example.edu/paper', tier=<SourceCredibilityTier.TIER_1: 'tier_1'>, credibility_score=0.95, verification_status='unverified', verification_count=0, last_verified=None, times_cited=0, citation_contexts=[], created_at=datetime.datetime(2025, 11, 13, 17, 25, 44, 912562), updated_at=datetime.datetime(2025, 11, 13, 17, 25, 44, 912564)).times_cited
___________ TestSourceCredibilityTracker.test_track_existing_source ____________
tests/unit/test_quality_validator.py:126: in test_track_existing_source
    assert record2.times_cited == 2
E   AssertionError: assert 1 == 2
E    +  where 1 = SourceCredibilityRecord(source_id='77540e9e-2df5-4262-a960-50bba5f0be7b', domain='example.edu', url='https://example.edu/paper', tier=<SourceCredibilityTier.TIER_1: 'tier_1'>, credibility_score=0.95, verification_status='unverified', verification_count=0, last_verified=None, times_cited=1, citation_contexts=[], created_at=datetime.datetime(2025, 11, 13, 17, 25, 44, 923680), updated_at=datetime.datetime(2025, 11, 13, 17, 25, 44, 923718)).times_cited
_____ TestQualityValidatorPreExecution.test_validate_clear_specific_query ______
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
__________ TestQualityValidatorPreExecution.test_validate_vague_query __________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
______ TestQualityValidatorPreExecution.test_validate_insufficient_budget ______
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
__________ TestQualityValidatorPreExecution.test_validate_short_query __________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
____ TestQualityValidatorPreExecution.test_permissive_gate_allows_marginal _____
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
______ TestQualityValidatorPreExecution.test_strict_gate_rejects_marginal ______
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
________ TestQualityValidatorPostExecution.test_validate_good_research _________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
____ TestQualityValidatorPostExecution.test_validate_poor_research_sources _____
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_____ TestQualityValidatorPostExecution.test_validate_insufficient_sources _____
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_____ TestQualityValidatorPostExecution.test_validate_with_contradictions ______
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
__ TestQualityValidatorPostExecution.test_no_sources_yields_zero_credibility ___
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_______ TestConfidenceCalculation.test_confidence_breakdown_high_quality _______
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
______ TestConfidenceCalculation.test_confidence_breakdown_components_sum ______
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
___________ TestConfidenceCalculation.test_confidence_empty_sources ____________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_________ TestContradictionDetection.test_detect_simple_contradiction __________
tests/unit/test_quality_validator.py:472: in test_detect_simple_contradiction
    assert len(contradictions) > 0
E   assert 0 > 0
E    +  where 0 = len([])
________ TestContradictionDetection.test_detect_multiple_contradictions ________
tests/unit/test_quality_validator.py:498: in test_detect_multiple_contradictions
    assert len(contradictions) > 0
E   assert 0 > 0
E    +  where 0 = len([])
__________ TestQualityScoringMethods.test_score_query_specificity_low __________
tests/unit/test_quality_validator.py:542: in test_score_query_specificity_low
    assert score < 0.6
E   assert 0.65 < 0.6
_________________ TestResearchOrchestrator.test_initialization _________________
tests/unit/test_research_orchestrator.py:61: in test_initialization
    patch("aris.core.research_orchestrator.DocumentStore"), \
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
/home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:1467: in get_original
    raise AttributeError(
E   AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
________________________ TestMCPSession.test_initialize ________________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
________________________ TestMCPSession.test_call_tool _________________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
______________________ TestMCPSession.test_error_handling ______________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
___________________ TestSequentialClient.test_start_session ____________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
___________________ TestSequentialClient.test_plan_research ____________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_______________ TestSequentialClient.test_plan_research_fallback _______________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
________________ TestSequentialClient.test_generate_hypotheses _________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
__________________ TestSequentialClient.test_test_hypothesis ___________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
________________ TestSequentialClient.test_synthesize_findings _________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
____________ TestSequentialClient.test_calculate_overall_confidence ____________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_______________________ TestSequentialClient.test_close ________________________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
_____________ TestSequentialClient.test_session_not_started_error ______________
async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
________ TestReasoningSchemas.test_hypothesis_result_confidence_change _________
tests/unit/test_sequential_client.py:348: in test_hypothesis_result_confidence_change
    assert result.confidence_change == 0.3
E   AssertionError: assert 0.30000000000000004 == 0.3
E    +  where 0.30000000000000004 = HypothesisResult(hypothesis=Hypothesis(statement='Test', confidence_prior=0.5, evidence_required=[], test_method='test'), confidence_posterior=0.8, supporting_evidence=[], contradicting_evidence=[], conclusion='Test').confidence_change
=============================== warnings summary ===============================
tests/integration/test_complete_workflow.py:173
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:173: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_complete_workflow.py:211
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:211: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_complete_workflow.py:252
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:252: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_complete_workflow.py:290
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:290: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_complete_workflow.py:339
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:339: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_complete_workflow.py:377
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:377: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_complete_workflow.py:396
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:396: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_complete_workflow.py:418
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:418: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_complete_workflow.py:442
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:442: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_complete_workflow.py:514
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:514: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_complete_workflow.py:552
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:552: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_complete_workflow.py:578
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:578: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_complete_workflow.py:600
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:600: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_complete_workflow.py:638
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:638: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_complete_workflow.py:688
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:688: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_complete_workflow.py:712
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:712: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_complete_workflow.py:747
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:747: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_complete_workflow.py:780
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:780: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_complete_workflow.py:812
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:812: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_complete_workflow.py:839
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:839: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_complete_workflow.py:857
  /mnt/projects/aris-tool/tests/integration/test_complete_workflow.py:857: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_critical_paths.py:49
  /mnt/projects/aris-tool/tests/integration/test_critical_paths.py:49: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_critical_paths.py:65
  /mnt/projects/aris-tool/tests/integration/test_critical_paths.py:65: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_critical_paths.py:119
  /mnt/projects/aris-tool/tests/integration/test_critical_paths.py:119: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_critical_paths.py:151
  /mnt/projects/aris-tool/tests/integration/test_critical_paths.py:151: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_critical_paths.py:212
  /mnt/projects/aris-tool/tests/integration/test_critical_paths.py:212: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_critical_paths.py:231
  /mnt/projects/aris-tool/tests/integration/test_critical_paths.py:231: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_critical_paths.py:251
  /mnt/projects/aris-tool/tests/integration/test_critical_paths.py:251: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_critical_paths.py:308
  /mnt/projects/aris-tool/tests/integration/test_critical_paths.py:308: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_critical_paths.py:332
  /mnt/projects/aris-tool/tests/integration/test_critical_paths.py:332: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_critical_paths.py:463
  /mnt/projects/aris-tool/tests/integration/test_critical_paths.py:463: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_critical_paths.py:477
  /mnt/projects/aris-tool/tests/integration/test_critical_paths.py:477: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_critical_paths.py:535
  /mnt/projects/aris-tool/tests/integration/test_critical_paths.py:535: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_critical_paths.py:553
  /mnt/projects/aris-tool/tests/integration/test_critical_paths.py:553: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_end_to_end_research.py:92
  /mnt/projects/aris-tool/tests/integration/test_end_to_end_research.py:92: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_end_to_end_research.py:122
  /mnt/projects/aris-tool/tests/integration/test_end_to_end_research.py:122: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_end_to_end_research.py:163
  /mnt/projects/aris-tool/tests/integration/test_end_to_end_research.py:163: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_end_to_end_research.py:196
  /mnt/projects/aris-tool/tests/integration/test_end_to_end_research.py:196: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_end_to_end_research.py:229
  /mnt/projects/aris-tool/tests/integration/test_end_to_end_research.py:229: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_end_to_end_research.py:257
  /mnt/projects/aris-tool/tests/integration/test_end_to_end_research.py:257: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_end_to_end_research.py:286
  /mnt/projects/aris-tool/tests/integration/test_end_to_end_research.py:286: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_end_to_end_research.py:308
  /mnt/projects/aris-tool/tests/integration/test_end_to_end_research.py:308: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_end_to_end_research.py:343
  /mnt/projects/aris-tool/tests/integration/test_end_to_end_research.py:343: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_performance_benchmarks.py:69
  /mnt/projects/aris-tool/tests/integration/test_performance_benchmarks.py:69: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_performance_benchmarks.py:87
  /mnt/projects/aris-tool/tests/integration/test_performance_benchmarks.py:87: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_performance_benchmarks.py:113
  /mnt/projects/aris-tool/tests/integration/test_performance_benchmarks.py:113: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_performance_benchmarks.py:136
  /mnt/projects/aris-tool/tests/integration/test_performance_benchmarks.py:136: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_performance_benchmarks.py:166
  /mnt/projects/aris-tool/tests/integration/test_performance_benchmarks.py:166: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_performance_benchmarks.py:194
  /mnt/projects/aris-tool/tests/integration/test_performance_benchmarks.py:194: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_performance_benchmarks.py:235
  /mnt/projects/aris-tool/tests/integration/test_performance_benchmarks.py:235: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_performance_benchmarks.py:249
  /mnt/projects/aris-tool/tests/integration/test_performance_benchmarks.py:249: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_performance_benchmarks.py:268
  /mnt/projects/aris-tool/tests/integration/test_performance_benchmarks.py:268: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_performance_benchmarks.py:285
  /mnt/projects/aris-tool/tests/integration/test_performance_benchmarks.py:285: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_performance_benchmarks.py:419
  /mnt/projects/aris-tool/tests/integration/test_performance_benchmarks.py:419: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_reasoning_workflow.py:50
  /mnt/projects/aris-tool/tests/integration/test_reasoning_workflow.py:50: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_reasoning_workflow.py:75
  /mnt/projects/aris-tool/tests/integration/test_reasoning_workflow.py:75: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_reasoning_workflow.py:137
  /mnt/projects/aris-tool/tests/integration/test_reasoning_workflow.py:137: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_reasoning_workflow.py:193
  /mnt/projects/aris-tool/tests/integration/test_reasoning_workflow.py:193: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_reasoning_workflow.py:249
  /mnt/projects/aris-tool/tests/integration/test_reasoning_workflow.py:249: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_reasoning_workflow.py:273
  /mnt/projects/aris-tool/tests/integration/test_reasoning_workflow.py:273: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_reasoning_workflow.py:307
  /mnt/projects/aris-tool/tests/integration/test_reasoning_workflow.py:307: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_reasoning_workflow.py:328
  /mnt/projects/aris-tool/tests/integration/test_reasoning_workflow.py:328: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_reasoning_workflow.py:341
  /mnt/projects/aris-tool/tests/integration/test_reasoning_workflow.py:341: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_reasoning_workflow.py:369
  /mnt/projects/aris-tool/tests/integration/test_reasoning_workflow.py:369: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/test_cost_manager.py:127
  /mnt/projects/aris-tool/tests/test_cost_manager.py:127: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/test_cost_manager.py:155
  /mnt/projects/aris-tool/tests/test_cost_manager.py:155: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/test_cost_manager.py:176
  /mnt/projects/aris-tool/tests/test_cost_manager.py:176: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/test_cost_manager.py:198
  /mnt/projects/aris-tool/tests/test_cost_manager.py:198: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/test_cost_manager.py:219
  /mnt/projects/aris-tool/tests/test_cost_manager.py:219: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/test_cost_manager.py:240
  /mnt/projects/aris-tool/tests/test_cost_manager.py:240: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/test_cost_manager.py:259
  /mnt/projects/aris-tool/tests/test_cost_manager.py:259: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/test_cost_manager.py:304
  /mnt/projects/aris-tool/tests/test_cost_manager.py:304: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/test_cost_manager.py:344
  /mnt/projects/aris-tool/tests/test_cost_manager.py:344: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_deduplication_gate.py:211
  /mnt/projects/aris-tool/tests/unit/test_deduplication_gate.py:211: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_deduplication_gate.py:346
  /mnt/projects/aris-tool/tests/unit/test_deduplication_gate.py:346: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_deduplication_gate.py:364
  /mnt/projects/aris-tool/tests/unit/test_deduplication_gate.py:364: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_deduplication_gate.py:400
  /mnt/projects/aris-tool/tests/unit/test_deduplication_gate.py:400: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_deduplication_gate.py:414
  /mnt/projects/aris-tool/tests/unit/test_deduplication_gate.py:414: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_quality_validator.py:154
  /mnt/projects/aris-tool/tests/unit/test_quality_validator.py:154: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_quality_validator.py:169
  /mnt/projects/aris-tool/tests/unit/test_quality_validator.py:169: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_quality_validator.py:183
  /mnt/projects/aris-tool/tests/unit/test_quality_validator.py:183: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_quality_validator.py:195
  /mnt/projects/aris-tool/tests/unit/test_quality_validator.py:195: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_quality_validator.py:207
  /mnt/projects/aris-tool/tests/unit/test_quality_validator.py:207: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_quality_validator.py:222
  /mnt/projects/aris-tool/tests/unit/test_quality_validator.py:222: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_quality_validator.py:293
  /mnt/projects/aris-tool/tests/unit/test_quality_validator.py:293: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_quality_validator.py:313
  /mnt/projects/aris-tool/tests/unit/test_quality_validator.py:313: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_quality_validator.py:327
  /mnt/projects/aris-tool/tests/unit/test_quality_validator.py:327: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_quality_validator.py:353
  /mnt/projects/aris-tool/tests/unit/test_quality_validator.py:353: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_quality_validator.py:369
  /mnt/projects/aris-tool/tests/unit/test_quality_validator.py:369: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_quality_validator.py:391
  /mnt/projects/aris-tool/tests/unit/test_quality_validator.py:391: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_quality_validator.py:422
  /mnt/projects/aris-tool/tests/unit/test_quality_validator.py:422: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_quality_validator.py:443
  /mnt/projects/aris-tool/tests/unit/test_quality_validator.py:443: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_research_orchestrator.py:124
  /mnt/projects/aris-tool/tests/unit/test_research_orchestrator.py:124: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_research_orchestrator.py:168
  /mnt/projects/aris-tool/tests/unit/test_research_orchestrator.py:168: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_research_orchestrator.py:205
  /mnt/projects/aris-tool/tests/unit/test_research_orchestrator.py:205: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_research_orchestrator.py:242
  /mnt/projects/aris-tool/tests/unit/test_research_orchestrator.py:242: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_research_orchestrator.py:262
  /mnt/projects/aris-tool/tests/unit/test_research_orchestrator.py:262: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_research_orchestrator.py:403
  /mnt/projects/aris-tool/tests/unit/test_research_orchestrator.py:403: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_sequential_client.py:24
  /mnt/projects/aris-tool/tests/unit/test_sequential_client.py:24: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_sequential_client.py:43
  /mnt/projects/aris-tool/tests/unit/test_sequential_client.py:43: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_sequential_client.py:63
  /mnt/projects/aris-tool/tests/unit/test_sequential_client.py:63: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_sequential_client.py:97
  /mnt/projects/aris-tool/tests/unit/test_sequential_client.py:97: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_sequential_client.py:111
  /mnt/projects/aris-tool/tests/unit/test_sequential_client.py:111: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_sequential_client.py:137
  /mnt/projects/aris-tool/tests/unit/test_sequential_client.py:137: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_sequential_client.py:155
  /mnt/projects/aris-tool/tests/unit/test_sequential_client.py:155: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_sequential_client.py:187
  /mnt/projects/aris-tool/tests/unit/test_sequential_client.py:187: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_sequential_client.py:225
  /mnt/projects/aris-tool/tests/unit/test_sequential_client.py:225: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_sequential_client.py:264
  /mnt/projects/aris-tool/tests/unit/test_sequential_client.py:264: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_sequential_client.py:294
  /mnt/projects/aris-tool/tests/unit/test_sequential_client.py:294: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_sequential_client.py:304
  /mnt/projects/aris-tool/tests/unit/test_sequential_client.py:304: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_tavily_client.py:69
  /mnt/projects/aris-tool/tests/unit/test_tavily_client.py:69: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_tavily_client.py:90
  /mnt/projects/aris-tool/tests/unit/test_tavily_client.py:90: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_tavily_client.py:108
  /mnt/projects/aris-tool/tests/unit/test_tavily_client.py:108: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_tavily_client.py:124
  /mnt/projects/aris-tool/tests/unit/test_tavily_client.py:124: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_tavily_client.py:139
  /mnt/projects/aris-tool/tests/unit/test_tavily_client.py:139: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_tavily_client.py:147
  /mnt/projects/aris-tool/tests/unit/test_tavily_client.py:147: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_tavily_client.py:164
  /mnt/projects/aris-tool/tests/unit/test_tavily_client.py:164: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_tavily_client.py:180
  /mnt/projects/aris-tool/tests/unit/test_tavily_client.py:180: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_tavily_client.py:201
  /mnt/projects/aris-tool/tests/unit/test_tavily_client.py:201: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_tavily_client.py:215
  /mnt/projects/aris-tool/tests/unit/test_tavily_client.py:215: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_tavily_client.py:230
  /mnt/projects/aris-tool/tests/unit/test_tavily_client.py:230: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_tavily_client.py:245
  /mnt/projects/aris-tool/tests/unit/test_tavily_client.py:245: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_tavily_client.py:271
  /mnt/projects/aris-tool/tests/unit/test_tavily_client.py:271: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_tavily_client.py:289
  /mnt/projects/aris-tool/tests/unit/test_tavily_client.py:289: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/unit/test_tavily_client.py:298
  /mnt/projects/aris-tool/tests/unit/test_tavily_client.py:298: PytestUnknownMarkWarning: Unknown pytest.mark.asyncio - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.asyncio

tests/integration/test_document_store.py: 42 warnings
tests/test_document_merger.py: 60 warnings
tests/unit/test_deduplication_gate.py: 8 warnings
tests/unit/test_document_finder.py: 4 warnings
tests/unit/test_quality_validator.py: 27 warnings
  /mnt/projects/aris-tool/.venv/lib/python3.13/site-packages/pydantic/main.py:250: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)

tests/integration/test_repositories.py: 32 warnings
tests/unit/test_database.py: 6 warnings
  /mnt/projects/aris-tool/.venv/lib/python3.13/site-packages/sqlalchemy/sql/schema.py:3624: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    return util.wrap_callable(lambda ctx: fn(), fn)  # type: ignore

tests/integration/test_repositories.py::TestRepositories::test_topic_repository
  /mnt/projects/aris-tool/src/aris/storage/repositories.py:118: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    topic.updated_at = datetime.utcnow()

tests/integration/test_repositories.py::TestRepositories::test_source_repository
  /mnt/projects/aris-tool/src/aris/storage/repositories.py:435: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    source.updated_at = datetime.utcnow()

tests/integration/test_repositories.py::TestRepositories::test_relationship_repository
  /mnt/projects/aris-tool/.venv/lib/python3.13/site-packages/sqlalchemy/util/langhelpers.py:485: ResourceWarning: unclosed database in <sqlite3.Connection object at 0x7f05a575b6a0>
    list(co.co_varnames[:nargs]),
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

tests/integration/test_repositories.py::TestRepositories::test_research_hop_repository
  /mnt/projects/aris-tool/src/aris/storage/repositories.py:741: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    hop.completed_at = datetime.utcnow()

tests/integration/test_repositories.py::TestRepositories::test_conflict_repository
  /mnt/projects/aris-tool/.venv/lib/python3.13/site-packages/sqlalchemy/util/langhelpers.py:1501: ResourceWarning: unclosed database in <sqlite3.Connection object at 0x7f05a57596c0>
    (k, obj.__dict__[k]) for k in names.difference(kw) if k in obj.__dict__
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

tests/integration/test_repositories.py::TestRepositories::test_conflict_repository
  /mnt/projects/aris-tool/src/aris/storage/repositories.py:854: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    conflict.resolved_at = datetime.utcnow()

tests/integration/test_repositories.py::TestRepositories::test_conflict_repository
  /mnt/projects/aris-tool/src/aris/storage/repositories.py:855: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    conflict.updated_at = datetime.utcnow()

tests/test_cost_manager.py::TestCostBreakdown::test_cost_breakdown_creation
tests/test_cost_manager.py::TestCostBreakdown::test_cost_breakdown_to_dict
tests/test_cost_manager.py::TestCostManager::test_clear_session_cache
  <string>:7: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).

tests/test_cost_manager.py::TestBudgetAlert::test_budget_alert_creation
tests/test_cost_manager.py::TestBudgetAlert::test_budget_alert_to_dict
  <string>:8: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).

tests/test_document_merger.py::TestMergeStrategies::test_merge_append_strategy
tests/test_document_merger.py::TestMergeReporting::test_merge_report_structure
tests/test_document_merger.py::TestMergeReporting::test_merge_log_entries
tests/test_document_merger.py::TestEdgeCases::test_merge_empty_content
tests/test_document_merger.py::TestIntegrationScenarios::test_multiple_sequential_merges
tests/test_document_merger.py::TestIntegrationScenarios::test_multiple_sequential_merges
  /mnt/projects/aris-tool/src/aris/core/document_merger.py:187: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    timestamp = datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S")

tests/test_document_merger.py: 17 warnings
  /mnt/projects/aris-tool/src/aris/core/document_merger.py:163: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    merged.metadata.updated_at = datetime.utcnow()

tests/test_document_merger.py: 17 warnings
  /mnt/projects/aris-tool/src/aris/core/document_merger.py:66: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    self.detected_at = datetime.utcnow()

tests/test_document_merger.py::TestMergeReporting::test_merge_report_structure
tests/test_document_merger.py::TestMergeReporting::test_merge_log_entries
tests/test_document_merger.py::TestIntegrationScenarios::test_full_merge_workflow
  /mnt/projects/aris-tool/src/aris/core/document_merger.py:577: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    "timestamp": datetime.utcnow().isoformat(),

tests/unit/test_database.py::TestDatabaseManager::test_session_scope_rollback
  /home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/weakref.py:428: ResourceWarning: unclosed database in <sqlite3.Connection object at 0x7f05a5a3e7a0>
    self.data[ref(key, self._remove)] = value
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

tests/unit/test_database.py::TestDatabaseManager::test_session_scope_rollback
  /home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/weakref.py:428: ResourceWarning: unclosed database in <sqlite3.Connection object at 0x7f05a5419120>
    self.data[ref(key, self._remove)] = value
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

tests/unit/test_deduplication_gate.py::TestDeduplicationGate::test_topic_overlap_calculation
  /mnt/projects/aris-tool/.venv/lib/python3.13/site-packages/sqlalchemy/engine/default.py:1796: ResourceWarning: unclosed database in <sqlite3.Connection object at 0x7f05a5c714e0>
    def get_result_processor(self, type_, colname, coltype):
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

tests/unit/test_deduplication_gate.py::TestDeduplicationGate::test_topic_overlap_calculation
  /mnt/projects/aris-tool/.venv/lib/python3.13/site-packages/sqlalchemy/engine/default.py:1796: ResourceWarning: unclosed database in <sqlite3.Connection object at 0x7f05a5a3de40>
    def get_result_processor(self, type_, colname, coltype):
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

tests/unit/test_deduplication_gate.py::TestDeduplicationGate::test_topic_overlap_calculation
  /mnt/projects/aris-tool/.venv/lib/python3.13/site-packages/sqlalchemy/engine/default.py:1796: ResourceWarning: unclosed database in <sqlite3.Connection object at 0x7f05a5a3d3f0>
    def get_result_processor(self, type_, colname, coltype):
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

tests/unit/test_document_finder.py::TestFindByTopics::test_find_by_topics_with_results
  /mnt/projects/aris-tool/tests/unit/test_document_finder.py:253: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    doc1.updated_at = datetime.utcnow()

tests/unit/test_document_finder.py::TestFindByTopics::test_find_by_topics_respects_confidence_filter
  /mnt/projects/aris-tool/tests/unit/test_document_finder.py:284: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    doc_high.updated_at = datetime.utcnow()

tests/unit/test_document_finder.py::TestFindByTopics::test_find_by_topics_respects_confidence_filter
  /mnt/projects/aris-tool/tests/unit/test_document_finder.py:290: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    doc_low.updated_at = datetime.utcnow()

tests/unit/test_document_finder.py::TestFindByTopics::test_find_by_topics_respects_status_filter
  /mnt/projects/aris-tool/tests/unit/test_document_finder.py:321: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    doc1.updated_at = datetime.utcnow()

tests/unit/test_document_finder.py::TestFindByTopics::test_find_by_topics_respects_status_filter
  /mnt/projects/aris-tool/tests/unit/test_document_finder.py:327: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    doc2.updated_at = datetime.utcnow()

tests/unit/test_document_finder.py::TestFindByTopics::test_find_by_topics_sorted_by_recency
  /mnt/projects/aris-tool/tests/unit/test_document_finder.py:353: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    now = datetime.utcnow()

tests/unit/test_document_finder.py::TestRankByRelevance::test_rank_by_relevance_applies_confidence_boost
  /mnt/projects/aris-tool/tests/unit/test_document_finder.py:423: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    updated_at=datetime.utcnow(),

tests/unit/test_document_finder.py::TestRankByRelevance::test_rank_by_relevance_applies_confidence_boost
  /mnt/projects/aris-tool/tests/unit/test_document_finder.py:434: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    updated_at=datetime.utcnow(),

tests/unit/test_document_finder.py::TestRankByRelevance::test_rank_by_relevance_applies_confidence_boost
tests/unit/test_document_finder.py::TestRankByRelevance::test_rank_by_relevance_applies_length_boost
  /mnt/projects/aris-tool/src/aris/core/document_finder.py:262: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    now = datetime.utcnow()

tests/unit/test_document_finder.py::TestRankByRelevance::test_rank_by_relevance_applies_length_boost
  /mnt/projects/aris-tool/tests/unit/test_document_finder.py:459: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    updated_at=datetime.utcnow(),

tests/unit/test_document_finder.py::TestRankByRelevance::test_rank_by_relevance_applies_length_boost
  /mnt/projects/aris-tool/tests/unit/test_document_finder.py:470: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    updated_at=datetime.utcnow(),

tests/unit/test_document_finder.py::TestIndexDocument::test_index_document_success
  /mnt/projects/aris-tool/src/aris/core/document_finder.py:381: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    metadata={"indexed_at": datetime.utcnow().isoformat()},

tests/unit/test_quality_validator.py::TestSourceCredibilityTracker::test_track_existing_source
  /mnt/projects/aris-tool/src/aris/core/quality_validator.py:125: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    record.updated_at = datetime.utcnow()

tests/unit/test_quality_validator.py::TestSourceCredibilityTracker::test_verify_source
  /mnt/projects/aris-tool/src/aris/core/quality_validator.py:173: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    record.last_verified = datetime.utcnow()

tests/unit/test_quality_validator.py::TestQualityScoringMethods::test_score_recency_recent
  /mnt/projects/aris-tool/tests/unit/test_quality_validator.py:587: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    retrieved_at=datetime.utcnow() - timedelta(days=10),

tests/unit/test_quality_validator.py::TestQualityScoringMethods::test_score_recency_recent
tests/unit/test_quality_validator.py::TestQualityScoringMethods::test_score_recency_old
  /mnt/projects/aris-tool/src/aris/core/quality_validator.py:694: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    now = datetime.utcnow()

tests/unit/test_quality_validator.py::TestQualityScoringMethods::test_score_recency_old
  /mnt/projects/aris-tool/tests/unit/test_quality_validator.py:601: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).
    retrieved_at=datetime.utcnow() - timedelta(days=1000),

tests/unit/test_sequential_client.py::TestSequentialClient::test_generate_hypotheses
  /home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:2193: ResourceWarning: unclosed database in <sqlite3.Connection object at 0x7f05a6b8dd50>
    setattr(_type, entry, MagicProxy(entry, self))
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

tests/unit/test_sequential_client.py::TestSequentialClient::test_generate_hypotheses
  /home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:2193: ResourceWarning: unclosed database in <sqlite3.Connection object at 0x7f05a572c220>
    setattr(_type, entry, MagicProxy(entry, self))
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

tests/unit/test_sequential_client.py::TestSequentialClient::test_generate_hypotheses
  /home/linuxbrew/.linuxbrew/opt/python@3.13/lib/python3.13/unittest/mock.py:2193: ResourceWarning: unclosed database in <sqlite3.Connection object at 0x7f05a5759e40>
    setattr(_type, entry, MagicProxy(entry, self))
  Enable tracemalloc to get traceback where the object was allocated.
  See https://docs.pytest.org/en/stable/how-to/capture-warnings.html#resource-warnings for more info.

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED tests/integration/test_cli_integration.py::TestCLIIntegration::test_full_initialization_workflow - assert 1 == 0
 +  where 1 = <Result SystemExit(1)>.exit_code
FAILED tests/integration/test_cli_integration.py::TestCLIIntegration::test_status_after_init - assert 1 == 0
 +  where 1 = <Result SystemExit(1)>.exit_code
FAILED tests/integration/test_cli_integration.py::TestCLIIntegration::test_json_output_mode - assert 1 == 0
 +  where 1 = <Result SystemExit(1)>.exit_code
FAILED tests/integration/test_cli_integration.py::TestCLIIntegration::test_db_commands_workflow - assert 1 == 0
 +  where 1 = <Result SystemExit(1)>.exit_code
FAILED tests/integration/test_cli_integration.py::TestCLIIntegration::test_placeholder_commands_accessible - assert 1 == 0
 +  where 1 = <Result SystemExit(1)>.exit_code
FAILED tests/integration/test_cli_integration.py::TestCLIOutputFormats::test_verbose_output - assert 1 == 0
 +  where 1 = <Result SystemExit(1)>.exit_code
FAILED tests/integration/test_complete_workflow.py::TestCostTrackingAndBudget::test_cost_operation_tracking - AttributeError: 'CostTracker' object has no attribute 'track_operation'. Did you mean: 'record_operation'?
FAILED tests/integration/test_complete_workflow.py::TestCostTrackingAndBudget::test_budget_limit_enforcement - TypeError: CostTracker.__init__() got an unexpected keyword argument 'budget_limit'
FAILED tests/integration/test_complete_workflow.py::TestCriticalPaths::test_git_operation_failure_handling - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_critical_paths.py::TestCriticalPath_CostTracking::test_cost_tracking_accuracy - TypeError: CostTracker.__init__() got an unexpected keyword argument 'budget_limit'
FAILED tests/integration/test_critical_paths.py::TestCriticalPath_CostTracking::test_budget_limit_enforcement - TypeError: CostTracker.__init__() got an unexpected keyword argument 'budget_limit'
FAILED tests/integration/test_critical_paths.py::TestCriticalPath_QualityValidation::test_confidence_scoring - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_critical_paths.py::TestCriticalPath_QualityValidation::test_quality_threshold_enforcement - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_document_store.py::TestDocumentSave::test_save_new_document - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_document_store.py::TestDocumentSave::test_save_creates_directory - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_document_store.py::TestDocumentSave::test_save_creates_git_commit - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_document_store.py::TestDocumentSave::test_save_with_custom_commit_message - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_document_store.py::TestDocumentSave::test_save_update_operation - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_document_store.py::TestDocumentSave::test_save_preserves_metadata - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_document_store.py::TestDocumentLoad::test_load_existing_document - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_document_store.py::TestDocumentLoad::test_load_nonexistent_document_raises_error - AssertionError: Regex pattern did not match.
  Expected regex: 'does not exist'
  Actual message: 'Document not found: /tmp/tmpldrcq3s2/research/nonexistent.md'
FAILED tests/integration/test_document_store.py::TestDocumentLoad::test_load_document_from_commit - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_document_store.py::TestVersionHistory::test_get_versions_single_version - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_document_store.py::TestVersionHistory::test_get_versions_multiple_versions - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_document_store.py::TestVersionHistory::test_get_versions_with_limit - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_document_store.py::TestDiffOperations::test_diff_between_versions - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_document_store.py::TestDiffOperations::test_diff_with_current - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_document_store.py::TestRestoreOperations::test_restore_to_previous_version - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_document_store.py::TestRestoreOperations::test_restore_creates_backup - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_document_store.py::TestRepositoryStatus::test_get_status_clean - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_document_store.py::TestRepositoryStatus::test_get_status_with_uncommitted - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_document_store.py::TestRepositoryStatus::test_has_uncommitted_changes - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_document_store.py::TestDocumentList::test_list_all_documents - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_document_store.py::TestDocumentList::test_list_documents_with_topic_filter - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_document_store.py::TestDocumentList::test_list_documents_with_status_filter - AttributeError: 'DocumentStore' object has no attribute 'save_document'. Did you mean: 'create_document'?
FAILED tests/integration/test_end_to_end_research.py::TestEndToEndResearch::test_complete_workflow - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_end_to_end_research.py::TestEndToEndResearch::test_multi_hop_workflow - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_end_to_end_research.py::TestEndToEndResearch::test_progress_tracking_integration - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_end_to_end_research.py::TestEndToEndResearch::test_document_creation_integration - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_end_to_end_research.py::TestEndToEndResearch::test_error_recovery - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_end_to_end_research.py::TestEndToEndResearch::test_budget_enforcement - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_end_to_end_research.py::TestReasoningEngineIntegration::test_reasoning_engine_hypothesis_workflow - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_end_to_end_research.py::TestReasoningEngineIntegration::test_confidence_based_early_stopping - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_end_to_end_research.py::TestAsyncContextManager::test_context_manager_usage - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_performance_benchmarks.py::TestCostTrackingPerformance::test_cost_operation_tracking_performance - AttributeError: 'CostTracker' object has no attribute 'track_operation'. Did you mean: 'record_operation'?
FAILED tests/integration/test_performance_benchmarks.py::TestCostTrackingPerformance::test_cost_summary_generation_performance - AttributeError: 'CostTracker' object has no attribute 'track_operation'. Did you mean: 'record_operation'?
FAILED tests/integration/test_performance_benchmarks.py::TestProgressTrackingPerformance::test_hop_recording_performance - AttributeError: 'ProgressTracker' object has no attribute 'record_hop'
FAILED tests/integration/test_performance_benchmarks.py::TestProgressTrackingPerformance::test_stats_computation_performance - AttributeError: 'ProgressTracker' object has no attribute 'record_hop'
FAILED tests/integration/test_reasoning_workflow.py::TestReasoningEngine::test_analyze_query - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_reasoning_workflow.py::TestReasoningEngine::test_execute_research_hop - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_reasoning_workflow.py::TestReasoningEngine::test_multi_hop_research_early_stop - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_reasoning_workflow.py::TestReasoningEngine::test_multi_hop_research_max_hops - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_reasoning_workflow.py::TestReasoningEngine::test_gather_evidence_error_handling - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_reasoning_workflow.py::TestReasoningEngine::test_refine_hypothesis - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_reasoning_workflow.py::TestReasoningEngine::test_generate_follow_up_queries - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_reasoning_workflow.py::TestReasoningEngine::test_cost_tracking - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_reasoning_workflow.py::TestReasoningEngine::test_context_management - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_reasoning_workflow.py::TestReasoningEngine::test_async_context_manager - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/integration/test_repositories.py::TestRepositories::test_document_repository - sqlalchemy.exc.InvalidRequestError: The unique() method must be invoked on this Result, as it contains results that include joined eager loads against collections
FAILED tests/integration/test_repositories.py::TestRepositories::test_research_session_repository - sqlalchemy.exc.InvalidRequestError: The unique() method must be invoked on this Result, as it contains results that include joined eager loads against collections
FAILED tests/test_cost_manager.py::TestCostBreakdown::test_cost_breakdown_creation - assert 0.060000000000000005 == 0.06
 +  where 0.060000000000000005 = CostBreakdown(tavily_cost=0.05, llm_tokens=1000, llm_cost=0.01, total_cost=0.060000000000000005, timestamp=datetime.datetime(2025, 11, 13, 17, 25, 29, 487914)).total_cost
FAILED tests/test_cost_manager.py::TestCostManager::test_track_hop_cost_with_calculations - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/test_cost_manager.py::TestCostManager::test_track_hop_cost_with_overrides - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/test_cost_manager.py::TestCostManager::test_budget_threshold_75_percent - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/test_cost_manager.py::TestCostManager::test_budget_threshold_90_percent - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/test_cost_manager.py::TestCostManager::test_budget_threshold_critical - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/test_cost_manager.py::TestCostManager::test_can_perform_operation_within_budget - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/test_cost_manager.py::TestCostManager::test_can_perform_operation_exceeds_budget - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/test_cost_manager.py::TestCostIntegration::test_multiple_hops_cost_accumulation - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/test_cost_manager.py::TestCostIntegration::test_export_cost_history_json - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/test_document_merger.py::TestMergeStrategies::test_invalid_merge_strategy - AttributeError: 'str' object has no attribute 'value'
FAILED tests/test_document_merger.py::TestMetadataMerge::test_merge_questions - AssertionError: assert set() == {'What is deep learning?', 'How does ML work?', 'What is AI?'}
  
  Extra items in the right set:
  'What is deep learning?'
  'How does ML work?'
  'What is AI?'
  
  Full diff:
  + set()
  - {
  -     'How does ML work?',
  -     'What is AI?',
  -     'What is deep learning?',
  - }
FAILED tests/test_document_merger.py::TestConflictDetection::test_detect_content_contradictions - pydantic_core._pydantic_core.ValidationError: 1 validation error for DocumentMetadata
purpose
  Field required [type=missing, input_value={'title': 'Test'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.12/v/missing
FAILED tests/test_document_merger.py::TestConflictDetection::test_no_conflict_similar_docs - pydantic_core._pydantic_core.ValidationError: 1 validation error for DocumentMetadata
purpose
  Field required [type=missing, input_value={'title': 'Research', 'to...I'], 'confidence': 0.75}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.12/v/missing
FAILED tests/test_document_merger.py::TestMergeReporting::test_conflict_recording - pydantic_core._pydantic_core.ValidationError: 1 validation error for DocumentMetadata
purpose
  Field required [type=missing, input_value={'title': 'Test', 'confidence': 0.75}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.12/v/missing
FAILED tests/test_document_merger.py::TestIntegrationScenarios::test_full_merge_workflow - KeyError: 'strategy'
FAILED tests/unit/storage/test_vector_store.py::TestVectorStoreInitialization::test_init_persistent - aris.storage.vector_store.VectorStoreError: Failed to initialize vector store: An instance of Chroma already exists for ephemeral with different settings
FAILED tests/unit/storage/test_vector_store.py::TestUpdateDocument::test_update_nonexistent_document - assert None is not None
FAILED tests/unit/storage/test_vector_store.py::TestDeleteDocument::test_delete_updates_count - assert 14 == 2
FAILED tests/unit/storage/test_vector_store.py::TestDeleteAll::test_delete_all_documents - assert 18 == 5
FAILED tests/unit/storage/test_vector_store.py::TestCollectionStats::test_stats_after_delete - assert 2 == 1
FAILED tests/unit/test_cli.py::TestInitCommand::test_init_basic - AssertionError: assert 'Initialized ARIS project' in '\u26a0\ufe0f  Warning: Project already initialized\n'
 +  where '\u26a0\ufe0f  Warning: Project already initialized\n' = <Result okay>.output
FAILED tests/unit/test_cli.py::TestInitCommand::test_init_with_profile - AssertionError: assert 'production' in '\u26a0\ufe0f  warning: project already initialized\n'
 +  where '\u26a0\ufe0f  warning: project already initialized\n' = <built-in method lower of str object at 0x7f05a5400490>()
 +    where <built-in method lower of str object at 0x7f05a5400490> = '\u26a0\ufe0f  Warning: Project already initialized\n'.lower
 +      where '\u26a0\ufe0f  Warning: Project already initialized\n' = <Result okay>.output
FAILED tests/unit/test_cli.py::TestStatusCommand::test_status_basic - assert 1 == 0
 +  where 1 = <Result SystemExit(1)>.exit_code
FAILED tests/unit/test_cli.py::TestStatusCommand::test_status_json - assert 1 == 0
 +  where 1 = <Result SystemExit(1)>.exit_code
FAILED tests/unit/test_cli.py::TestShowCommand::test_show_metadata_only - assert 1 == 0
 +  where 1 = <Result SystemExit(1)>.exit_code
FAILED tests/unit/test_cli.py::TestPlaceholderCommands::test_research_command - assert 1 == 0
 +  where 1 = <Result SystemExit(1)>.exit_code
FAILED tests/unit/test_cli.py::TestPlaceholderCommands::test_session_commands - assert 2 == 0
 +  where 2 = <Result SystemExit(2)>.exit_code
FAILED tests/unit/test_cli.py::TestDBCommands::test_db_status - assert 1 == 0
 +  where 1 = <Result SystemExit(1)>.exit_code
FAILED tests/unit/test_cli.py::TestGitCommands::test_git_status - assert 1 == 0
 +  where 1 = <Result SystemExit(1)>.exit_code
FAILED tests/unit/test_config.py::TestConfigManager::test_get_api_key_from_keyring - AssertionError: assert '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' == 'keyring_key_123'
  
  - keyring_key_123
  + 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
FAILED tests/unit/test_config.py::TestConfigManager::test_validate_missing_required_keys - assert True is False
FAILED tests/unit/test_config.py::TestConfigManager::test_get_config_summary_masked - AssertionError: assert 'tvly-dev...HKjC' == 'Not set'
  
  - Not set
  + tvly-dev...HKjC
FAILED tests/unit/test_config.py::TestConfigurationIntegration::test_end_to_end_configuration_flow - assert not True
FAILED tests/unit/test_config.py::TestConfigurationIntegration::test_keyring_fallback_to_env - AssertionError: assert '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' == 'env_key_123'
  
  - env_key_123
  + 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
FAILED tests/unit/test_config.py::TestConfigurationIntegration::test_keyring_overrides_env - AssertionError: assert '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' == 'keyring_key'
  
  - keyring_key
  + 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
FAILED tests/unit/test_database.py::TestDatabaseManager::test_create_tables - AssertionError: assert {'quality_metrics', 'document_sources', 'topics', 'research_sessions', 'conflicts', 'sources', 'contradiction_detection', 'relationships', 'source_credibility', 'documents', 'validation_rule_history', 'research_hops'} == {'document_sources', 'topics', 'conflicts', 'research_sessions', 'sources', 'relationships', 'documents', 'research_hops'}
  
  Extra items in the left set:
  'quality_metrics'
  'source_credibility'
  'validation_rule_history'
  'contradiction_detection'
  
  Full diff:
    {
        'conflicts',
  +     'contradiction_detection',
        'document_sources',
        'documents',
  +     'quality_metrics',
        'relationships',
        'research_hops',
        'research_sessions',
  +     'source_credibility',
        'sources',
        'topics',
  +     'validation_rule_history',
    }
FAILED tests/unit/test_deduplication_gate.py::TestDeduplicationGate::test_no_similar_documents_creates_new - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_deduplication_gate.py::TestDeduplicationGate::test_topic_overlap_description - AssertionError: assert 'AI' in 'ai'
FAILED tests/unit/test_deduplication_gate.py::TestDeduplicationGate::test_word_extraction_for_similarity - assert 0.5 > 0.5
FAILED tests/unit/test_deduplication_gate.py::TestDeduplicationGateIntegration::test_empty_database_creates_new - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_deduplication_gate.py::TestDeduplicationGateIntegration::test_decision_logging - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_deduplication_gate.py::TestEdgeCases::test_empty_content - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_deduplication_gate.py::TestEdgeCases::test_empty_topics - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_document_finder.py::TestFindSimilarDocuments::test_find_similar_documents_with_results - AttributeError: type object 'DocumentStatus' has no attribute 'PUBLISHED'
FAILED tests/unit/test_document_finder.py::TestRankByRelevance::test_rank_by_relevance_applies_length_boost - AssertionError: assert 13 > 1000
 +  where 13 = len('short content')
 +    where 'short content' = Document(metadata=DocumentMetadata(id=UUID('76adc506-0c5d-47ec-99dc-426fb2885e7c'), title='Short', purpose='test', topics=[], questions_answered=[], status=<DocumentStatus.DRAFT: 'draft'>, created_at=datetime.datetime(2025, 11, 13, 17, 25, 44, 361857), updated_at=datetime.datetime(2025, 11, 13, 17, 25, 44, 361841), last_validated=None, confidence=0.8, source_count=0, related_docs=[], supersedes=None, superseded_by=None), content='short content', file_path=PosixPath('research/test/short.md'), embedding_id=None).content
 +  and   1000 = len('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')
 +    where 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx' = Document(metadata=DocumentMetadata(id=UUID('eb221bc9-46b2-4fa7-80ca-ac2bb4bc1d00'), title='Long', purpose='test', topics=[], questions_answered=[], status=<DocumentStatus.DRAFT: 'draft'>, created_at=datetime.datetime(2025, 11, 13, 17, 25, 44, 361876), updated_at=datetime.datetime(2025, 11, 13, 17, 25, 44, 361870), last_validated=None, confidence=0.8, source_count=0, related_docs=[], supersedes=None, superseded_by=None), content='xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx', file_path=PosixPath('research/test/long.md'), embedding_id=None).content
FAILED tests/unit/test_git_manager.py::TestDiffOperations::test_diff_with_working_tree - AssertionError: assert '-Committed' in 'diff --git a/test.md b/test.md\nindex afa3ae0..dcab6f5 100644\n--- a/test.md\n+++ b/test.md\n@@ -1 +1 @@\n-# Committed\n\\ No newline at end of file\n+# Modified\n\\ No newline at end of file'
FAILED tests/unit/test_quality_validator.py::TestSourceCredibilityTracker::test_track_new_source - AssertionError: assert 0 == 1
 +  where 0 = SourceCredibilityRecord(source_id='d0ccc056-0978-46ad-bf38-4bec708053ce', domain='example.edu', url='https://example.edu/paper', tier=<SourceCredibilityTier.TIER_1: 'tier_1'>, credibility_score=0.95, verification_status='unverified', verification_count=0, last_verified=None, times_cited=0, citation_contexts=[], created_at=datetime.datetime(2025, 11, 13, 17, 25, 44, 912562), updated_at=datetime.datetime(2025, 11, 13, 17, 25, 44, 912564)).times_cited
FAILED tests/unit/test_quality_validator.py::TestSourceCredibilityTracker::test_track_existing_source - AssertionError: assert 1 == 2
 +  where 1 = SourceCredibilityRecord(source_id='77540e9e-2df5-4262-a960-50bba5f0be7b', domain='example.edu', url='https://example.edu/paper', tier=<SourceCredibilityTier.TIER_1: 'tier_1'>, credibility_score=0.95, verification_status='unverified', verification_count=0, last_verified=None, times_cited=1, citation_contexts=[], created_at=datetime.datetime(2025, 11, 13, 17, 25, 44, 923680), updated_at=datetime.datetime(2025, 11, 13, 17, 25, 44, 923718)).times_cited
FAILED tests/unit/test_quality_validator.py::TestQualityValidatorPreExecution::test_validate_clear_specific_query - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_quality_validator.py::TestQualityValidatorPreExecution::test_validate_vague_query - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_quality_validator.py::TestQualityValidatorPreExecution::test_validate_insufficient_budget - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_quality_validator.py::TestQualityValidatorPreExecution::test_validate_short_query - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_quality_validator.py::TestQualityValidatorPreExecution::test_permissive_gate_allows_marginal - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_quality_validator.py::TestQualityValidatorPreExecution::test_strict_gate_rejects_marginal - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_quality_validator.py::TestQualityValidatorPostExecution::test_validate_good_research - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_quality_validator.py::TestQualityValidatorPostExecution::test_validate_poor_research_sources - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_quality_validator.py::TestQualityValidatorPostExecution::test_validate_insufficient_sources - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_quality_validator.py::TestQualityValidatorPostExecution::test_validate_with_contradictions - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_quality_validator.py::TestQualityValidatorPostExecution::test_no_sources_yields_zero_credibility - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_quality_validator.py::TestConfidenceCalculation::test_confidence_breakdown_high_quality - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_quality_validator.py::TestConfidenceCalculation::test_confidence_breakdown_components_sum - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_quality_validator.py::TestConfidenceCalculation::test_confidence_empty_sources - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_quality_validator.py::TestContradictionDetection::test_detect_simple_contradiction - assert 0 > 0
 +  where 0 = len([])
FAILED tests/unit/test_quality_validator.py::TestContradictionDetection::test_detect_multiple_contradictions - assert 0 > 0
 +  where 0 = len([])
FAILED tests/unit/test_quality_validator.py::TestQualityScoringMethods::test_score_query_specificity_low - assert 0.65 < 0.6
FAILED tests/unit/test_research_orchestrator.py::TestResearchOrchestrator::test_initialization - AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
FAILED tests/unit/test_sequential_client.py::TestMCPSession::test_initialize - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_sequential_client.py::TestMCPSession::test_call_tool - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_sequential_client.py::TestMCPSession::test_error_handling - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_sequential_client.py::TestSequentialClient::test_start_session - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_sequential_client.py::TestSequentialClient::test_plan_research - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_sequential_client.py::TestSequentialClient::test_plan_research_fallback - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_sequential_client.py::TestSequentialClient::test_generate_hypotheses - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_sequential_client.py::TestSequentialClient::test_test_hypothesis - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_sequential_client.py::TestSequentialClient::test_synthesize_findings - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_sequential_client.py::TestSequentialClient::test_calculate_overall_confidence - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_sequential_client.py::TestSequentialClient::test_close - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_sequential_client.py::TestSequentialClient::test_session_not_started_error - Failed: async def functions are not natively supported.
You need to install a suitable plugin for your async framework, for example:
  - anyio
  - pytest-asyncio
  - pytest-tornasync
  - pytest-trio
  - pytest-twisted
FAILED tests/unit/test_sequential_client.py::TestReasoningSchemas::test_hypothesis_result_confidence_change - AssertionError: assert 0.30000000000000004 == 0.3
 +  where 0.30000000000000004 = HypothesisResult(hypothesis=Hypothesis(statement='Test', confidence_prior=0.5, evidence_required=[], test_method='test'), confidence_posterior=0.8, supporting_evidence=[], contradicting_evidence=[], conclusion='Test').confidence_change
ERROR tests/integration/test_complete_workflow.py::TestCompleteWorkflow::test_query_to_document_creation_workflow - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestCompleteWorkflow::test_query_to_deduplication_and_update - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestCompleteWorkflow::test_workflow_git_integration - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestDeduplicationGateIntegration::test_duplicate_detection_workflow - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestDeduplicationGateIntegration::test_deduplication_action_execution - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestSessionPersistence::test_session_creation_and_persistence - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestSessionPersistence::test_session_resume - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestSessionPersistence::test_session_state_updates - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestSessionPersistence::test_multiple_session_isolation - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestCostTrackingAndBudget::test_cost_tracking_in_workflow - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestQualityValidationAndConfidence::test_confidence_scoring_in_workflow - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestQualityValidationAndConfidence::test_document_quality_metrics - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestQualityValidationAndConfidence::test_early_stopping_on_confidence - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestPerformanceBenchmarks::test_workflow_execution_time - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestPerformanceBenchmarks::test_document_store_batch_performance - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestPerformanceBenchmarks::test_deduplication_performance_scaling - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestPerformanceBenchmarks::test_session_recovery_time - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestIntegrationStress::test_concurrent_research_queries - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestIntegrationStress::test_large_document_handling - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestCriticalPaths::test_research_failure_recovery - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestCriticalPaths::test_document_update_failure_handling - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_complete_workflow.py::TestIntegrationHelpers::test_config_validation - pydantic_core._pydantic_core.ValidationError: 1 validation error for ArisConfig
budget_limit
  Extra inputs are not permitted [type=extra_forbidden, input_value=5.0, input_type=float]
    For further information visit https://errors.pydantic.dev/2.12/v/extra_forbidden
ERROR tests/integration/test_critical_paths.py::TestCriticalPath_QueryIngestion::test_query_acceptance_and_validation - pytest.PytestRemovedIn9Warning: 'test_query_acceptance_and_validation' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_critical_paths.py::TestCriticalPath_QueryIngestion::test_session_initialization - pytest.PytestRemovedIn9Warning: 'test_session_initialization' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_critical_paths.py::TestCriticalPath_Deduplication::test_duplicate_detection_flow - pytest.PytestRemovedIn9Warning: 'test_duplicate_detection_flow' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_critical_paths.py::TestCriticalPath_Deduplication::test_deduplication_decision_execution - pytest.PytestRemovedIn9Warning: 'test_deduplication_decision_execution' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_critical_paths.py::TestCriticalPath_DocumentStorage::test_document_save_and_retrieve - pytest.PytestRemovedIn9Warning: 'test_document_save_and_retrieve' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_critical_paths.py::TestCriticalPath_DocumentStorage::test_document_integrity_after_retrieval - pytest.PytestRemovedIn9Warning: 'test_document_integrity_after_retrieval' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_critical_paths.py::TestCriticalPath_DocumentStorage::test_bulk_document_operations - pytest.PytestRemovedIn9Warning: 'test_bulk_document_operations' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_critical_paths.py::TestCriticalPath_SessionPersistence::test_session_persistence_cycle - pytest.PytestRemovedIn9Warning: 'test_session_persistence_cycle' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_critical_paths.py::TestCriticalPath_SessionPersistence::test_session_state_transitions - pytest.PytestRemovedIn9Warning: 'test_session_state_transitions' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_critical_paths.py::TestCriticalPath_ErrorRecovery::test_error_recording_in_session - pytest.PytestRemovedIn9Warning: 'test_error_recording_in_session' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_critical_paths.py::TestCriticalPath_ErrorRecovery::test_session_recovery_after_failure - pytest.PytestRemovedIn9Warning: 'test_session_recovery_after_failure' requested an async fixture 'db_manager', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_performance_benchmarks.py::TestDocumentOperationsPerformance::test_single_document_save_performance - pytest.PytestRemovedIn9Warning: 'test_single_document_save_performance' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_performance_benchmarks.py::TestDocumentOperationsPerformance::test_bulk_document_save_performance - pytest.PytestRemovedIn9Warning: 'test_bulk_document_save_performance' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_performance_benchmarks.py::TestDocumentOperationsPerformance::test_document_retrieval_performance - pytest.PytestRemovedIn9Warning: 'test_document_retrieval_performance' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_performance_benchmarks.py::TestDocumentOperationsPerformance::test_document_with_large_content_performance - pytest.PytestRemovedIn9Warning: 'test_document_with_large_content_performance' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_performance_benchmarks.py::TestDeduplicationPerformance::test_deduplication_check_performance - pytest.PytestRemovedIn9Warning: 'test_deduplication_check_performance' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_performance_benchmarks.py::TestDeduplicationPerformance::test_deduplication_scaling_performance - pytest.PytestRemovedIn9Warning: 'test_deduplication_scaling_performance' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_performance_benchmarks.py::TestSessionOperationsPerformance::test_session_creation_performance - pytest.PytestRemovedIn9Warning: 'test_session_creation_performance' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_performance_benchmarks.py::TestSessionOperationsPerformance::test_session_state_update_performance - pytest.PytestRemovedIn9Warning: 'test_session_state_update_performance' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_performance_benchmarks.py::TestSessionOperationsPerformance::test_session_retrieval_performance - pytest.PytestRemovedIn9Warning: 'test_session_retrieval_performance' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_performance_benchmarks.py::TestSessionOperationsPerformance::test_bulk_session_operations_performance - pytest.PytestRemovedIn9Warning: 'test_bulk_session_operations_performance' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/integration/test_performance_benchmarks.py::TestEndToEndWorkflowPerformance::test_workflow_step_timing - pytest.PytestRemovedIn9Warning: 'test_workflow_step_timing' requested an async fixture 'benchmark_db', with no plugin or hook that handled it. This is usually an error, as pytest does not natively support it. This will turn into an error in pytest 9.
See: https://docs.pytest.org/en/stable/deprecations.html#sync-test-depending-on-async-fixture
ERROR tests/unit/storage/test_vector_store.py::TestPersistence::test_persist_to_disk - aris.storage.vector_store.VectorStoreError: Failed to initialize vector store: An instance of Chroma already exists for ephemeral with different settings
ERROR tests/unit/storage/test_vector_store.py::TestPersistence::test_persist_idempotent - aris.storage.vector_store.VectorStoreError: Failed to initialize vector store: An instance of Chroma already exists for ephemeral with different settings
ERROR tests/unit/test_document_finder.py::TestRankByRelevance::test_rank_by_relevance_applies_recency_boost - AttributeError: type object 'DocumentStatus' has no attribute 'PUBLISHED'
ERROR tests/unit/test_research_orchestrator.py::TestResearchOrchestrator::test_get_max_hops - AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
ERROR tests/unit/test_research_orchestrator.py::TestResearchOrchestrator::test_generate_title - AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
ERROR tests/unit/test_research_orchestrator.py::TestResearchOrchestrator::test_create_research_session - AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
ERROR tests/unit/test_research_orchestrator.py::TestResearchOrchestrator::test_create_research_session_with_cost_override - AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
ERROR tests/unit/test_research_orchestrator.py::TestResearchOrchestrator::test_create_research_session_budgets - AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
ERROR tests/unit/test_research_orchestrator.py::TestResearchExecution::test_execute_research_basic - AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
ERROR tests/unit/test_research_orchestrator.py::TestResearchExecution::test_execute_research_early_stopping - AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
ERROR tests/unit/test_research_orchestrator.py::TestResearchExecution::test_execute_research_budget_limit - AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
ERROR tests/unit/test_research_orchestrator.py::TestResearchExecution::test_execute_research_handles_errors - AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
ERROR tests/unit/test_research_orchestrator.py::TestProgressTracking::test_progress_tracking - AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
ERROR tests/unit/test_research_orchestrator.py::TestDocumentFormatting::test_format_research_findings - AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
ERROR tests/unit/test_research_orchestrator.py::TestDocumentFormatting::test_format_research_findings_with_gaps - AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
ERROR tests/unit/test_research_orchestrator.py::TestAsyncContextManager::test_async_context_manager - AttributeError: <module 'aris.core.research_orchestrator' from '/mnt/projects/aris-tool/src/aris/core/research_orchestrator.py'> does not have the attribute 'DocumentStore'
!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 200 failures !!!!!!!!!!!!!!!!!!!!!!!!!!
========== 140 failed, 221 passed, 386 warnings, 60 errors in 26.94s ===========
